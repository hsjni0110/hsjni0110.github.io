{"componentChunkName":"component---src-templates-blog-template-js","path":"/data-engineer-4/","result":{"data":{"cur":{"id":"ae0d9aaa-2a95-51c9-bef5-c10a82fd5f13","html":"<h2 id=\"제-4장-빅데이터의-축적\" style=\"position:relative;\"><a href=\"#%EC%A0%9C-4%EC%9E%A5-%EB%B9%85%EB%8D%B0%EC%9D%B4%ED%84%B0%EC%9D%98-%EC%B6%95%EC%A0%81\" aria-label=\"제 4장 빅데이터의 축적 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>제 4장. 빅데이터의 축적</h2>\n<h3 id=\"객체-스토리지와-데이터-수집\" style=\"position:relative;\"><a href=\"#%EA%B0%9D%EC%B2%B4-%EC%8A%A4%ED%86%A0%EB%A6%AC%EC%A7%80%EC%99%80-%EB%8D%B0%EC%9D%B4%ED%84%B0-%EC%88%98%EC%A7%91\" aria-label=\"객체 스토리지와 데이터 수집 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>객체 스토리지와 데이터 수집</h3>\n<br />\n<p>빅데이터의 경우 확장성이 높은 <strong>분산 스토리지</strong>에 데이터 수집/저장합니다.</p>\n<br />\n<p>우선 기본이 되는 것은 <strong>객체 스토리지</strong>입니다.</p>\n<br />\n<p>대표적으로 Hadoop의 HDFS, 클라우드 서비스의 Amazon S3가 유명합니다.</p>\n<br />\n<p>이러한 객체 스토리지는 다수의 컴퓨터를 사용해 파일을 여러 디스크에 복사하여 저장합니다.</p>\n<br />\n<p>즉 중복화 및 분산/저장을 실시하나 소규모 데이터에 대해서는 통신오버헤드가 생겨 적합하지는 않죠.</p>\n<br />\n<p>객체 스토리지(분산 스토리지)안에 데이터를 기록/수집하는 것은 어느정도 노력이 필요합니다.</p>\n<br />\n<p>너무 작은 데이터는 모아서 기록하고, 너무 큰 데이터는 분할해서 기록하는 것이 집계 효율을 올리고, 문제를 예방할 수 있습니다.</p>\n<br />\n<ul>\n<li><strong>데이터 수집</strong></li>\n</ul>\n<p>수집한 데이터를 가공하여 <span style=\"color:#2d3748; background-color:#fff5b1\">집계 효율이 좋은 분산 스토리지</span>를 만드는 일련의 프로세스</p>\n<br />\n<h3 id=\"벌크-형의-데이터-전송\" style=\"position:relative;\"><a href=\"#%EB%B2%8C%ED%81%AC-%ED%98%95%EC%9D%98-%EB%8D%B0%EC%9D%B4%ED%84%B0-%EC%A0%84%EC%86%A1\" aria-label=\"벌크 형의 데이터 전송 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>벌크 형의 데이터 전송</h3>\n<br />\n<p>데이터 전송 구조는 벌크 형과 스트리밍 형으로 나뉩니다.</p>\n<br />\n<p>먼저 벌크 형의 데이터 전송 구조는 ETL 서버 설치로 부터 시작됩니다.</p>\n<br />\n<p>이 ETL 서버를 통해서 DB 혹은 웹 서비스로부터 수집한 데이터를 표준적인 포맷(스키마리스 데이터)으로 변환합니다.</p>\n<br />\n<p>이때 벌크 형 도구로 데이터를 보내는 경우 파일 사이즈를 적정화 해야합니다.</p>\n<br />\n<p>그렇게 하기 위해 너무 많은 양의 데이터를 전송하거나 너무 적은 양의 데이터를 전송할 때, 적당량 데이터씩 시간을 두어 전송하도록 해야합니다.</p>\n<br />\n<p>이때 워크플로 관리도구를 통해 이러한 태스크 실행을 관리할 수 있습니다.</p>\n<br />\n<h3 id=\"스트리밍-형의-데이터-전송\" style=\"position:relative;\"><a href=\"#%EC%8A%A4%ED%8A%B8%EB%A6%AC%EB%B0%8D-%ED%98%95%EC%9D%98-%EB%8D%B0%EC%9D%B4%ED%84%B0-%EC%A0%84%EC%86%A1\" aria-label=\"스트리밍 형의 데이터 전송 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>스트리밍 형의 데이터 전송</h3>\n<br />\n<p>간단하게 말해 계속해서 전송되어 오는 작은 데이터를 취급하기 위한 데이터 전송입니다.</p>\n<br />\n<p>예를 들어 ‘웹 브라우저’, ‘모바일 앱’, ‘센서 기기’등에 해당됩니다.</p>\n<br />\n<p>이러한 경우, 데이터 전송의 공통점은 다수의 클라이언트에서 계속해서 작은 데이터가 전송된다는 겁니다.</p>\n<br />\n<p>일반적으로 이를 <strong>메시지 전송</strong>이라고 합니다.</p>\n<br />\n<p>메시지 전송을 할때는 통신 오버헤드가 커집니다. 즉, 이를 처리하는 서버 측에서 어느정도의 성능을 요구합니다.</p>\n<br />\n<p>방법은 두가지가 있습니다.</p>\n<br />\n<ol>\n<li>작은 데이터 쓰기에 적합한 NoSQL 사용</li>\n</ol>\n<br />\n<p>NoSQL 데이터베이스에 작은 데이터를 보관합니다. 이전에 말했듯이 Hive는 다른 DB로 부터 데이터를 불러들어 사용할 수 있어 Hive 쿼리 엔진을 통해 NoSQL 데이터베이스에 연결할 수 있습니다.</p>\n<br />\n<ol start=\"2\">\n<li>메시지 큐, 메시지 브로커의 사용</li>\n</ol>\n<br />\n<p>중계 시스템을 통해 일정한 간격으로 꺼내고 모아 분산 스토리지에 저장합니다.</p>\n<br />\n<h3 id=\"웹-브라우저에서의-메시지-전송\" style=\"position:relative;\"><a href=\"#%EC%9B%B9-%EB%B8%8C%EB%9D%BC%EC%9A%B0%EC%A0%80%EC%97%90%EC%84%9C%EC%9D%98-%EB%A9%94%EC%8B%9C%EC%A7%80-%EC%A0%84%EC%86%A1\" aria-label=\"웹 브라우저에서의 메시지 전송 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>웹 브라우저에서의 메시지 전송</h3>\n<br />\n<ol>\n<li>서버 상에서 데이터를 축적해 모아 보내기</li>\n</ol>\n<p>Fluentd, Logstash와 같은 서버 상주형 로그 수집 소프트웨어를 사용합니다.</p>\n<br />\n<ol start=\"2\">\n<li>웹 이벤트 트래킹</li>\n</ol>\n<p>자바스크립트를 사용해 웹 브라우저에서 직접 메시지를 보냅니다.</p>\n<br />\n<h3 id=\"모바일-앱으로부터의-메시지-전송\" style=\"position:relative;\"><a href=\"#%EB%AA%A8%EB%B0%94%EC%9D%BC-%EC%95%B1%EC%9C%BC%EB%A1%9C%EB%B6%80%ED%84%B0%EC%9D%98-%EB%A9%94%EC%8B%9C%EC%A7%80-%EC%A0%84%EC%86%A1\" aria-label=\"모바일 앱으로부터의 메시지 전송 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>모바일 앱으로부터의 메시지 전송</h3>\n<br />\n<p>통신 방법에 있어서는 웹 브라우저와 같이 HTTP 프로토콜 사용합니다.</p>\n<br />\n<ol>\n<li>MBaaS(Mobile Backend as a Service) 이용</li>\n</ol>\n<p>벡 엔드의 각종 서비스를 사용할 수 있는 MBaaS를 사용하여 수집합니다.</p>\n<br />\n<ol start=\"2\">\n<li>SDK를 사용하여 전송</li>\n</ol>\n<br />\n<h3 id=\"디바이스로부터의-메시지-전송\" style=\"position:relative;\"><a href=\"#%EB%94%94%EB%B0%94%EC%9D%B4%EC%8A%A4%EB%A1%9C%EB%B6%80%ED%84%B0%EC%9D%98-%EB%A9%94%EC%8B%9C%EC%A7%80-%EC%A0%84%EC%86%A1\" aria-label=\"디바이스로부터의 메시지 전송 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>디바이스로부터의 메시지 전송</h3>\n<br />\n<p>IoT 등의 디바이스로부터 메시지 전달은 아직 업계 표준이라 할 만한 것이 없이 많은 규격이 난무합니다.</p>\n<br />\n<p>그 중에 하나로 MQTT가 있습니다.</p>\n<br />\n<p>이는 전달/구독형 메시지 전송(Pub/Sub 형 메시지 전송)으로 불립니다.</p>\n<br />\n<p>토픽이라고 불리는 방을 구독하면 그 방을 구독한 사람에게 메시지가 전달되는 형식입니다.</p>\n<br />\n<p>MQTT 브로커가 구독자인 MQTT 구독자에게 메시지를 전달하는 겁니다.</p>\n<br />\n<h3 id=\"메시지-배송의-공통화\" style=\"position:relative;\"><a href=\"#%EB%A9%94%EC%8B%9C%EC%A7%80-%EB%B0%B0%EC%86%A1%EC%9D%98-%EA%B3%B5%ED%86%B5%ED%99%94\" aria-label=\"메시지 배송의 공통화 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>메시지 배송의 공통화</h3>\n<br />\n<p>메시지 배송 방식은 어디에서 데이터를 수집하느냐에 따라 달라집니다.</p>\n<br />\n<p>하지만 공통점은 메시지가 처음 생성되는 기기를 <strong>클라이언트</strong>, 제일 처음 메시지를 받는 서버를 <strong>프론트 엔드</strong>라고 부른다는 것.</p>\n<br />\n<p>그리고 이 프론트 엔드는 데이터 보호를 위한 일을 하며 메시지 브로커로 데이터를 전송하면 <strong>메시지 브로커</strong>가 분산 스토리지에 데이터를 저장한다는 것입니다.</p>\n<br />\n<hr>\n<h3 id=\"메시지-브로커\" style=\"position:relative;\"><a href=\"#%EB%A9%94%EC%8B%9C%EC%A7%80-%EB%B8%8C%EB%A1%9C%EC%BB%A4\" aria-label=\"메시지 브로커 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>메시지 브로커</h3>\n<br />\n<p>분산 스토리지에 들어오는 메시지를 마냥 기록하기만 한다면 부하 제어가 어려워 성능 한계에 도달하기 쉽습니다.</p>\n<br />\n<p>따라서 메시지 브로커가 일시적으로 데이터를 축적해야 합니다.</p>\n<br />\n<ul>\n<li><strong>메시지 브로커</strong></li>\n</ul>\n<p>데이터를 일시적으로 축적하는 중산층</p>\n<br />\n<p>빅데이터를 위한 <strong>분산형 메시지 브로커</strong>는 다음과 같습니다.</p>\n<br />\n<ul>\n<li><em>Apache Kafka</em></li>\n<li><em>Amazon Kinesis</em></li>\n</ul>\n<br />\n<ul>\n<li><strong>생산자</strong></li>\n</ul>\n<p>메시지 브로커에 데이터를 넣는(push) 것</p>\n<br />\n<ul>\n<li><strong>소비자</strong></li>\n</ul>\n<p>메시지 브로커로부터 데이터를 가져오는(pull) 것</p>\n<br />\n<p>메시지 브로커는 일정량의 데이터를 일정한 간격으로 분산 스토리지에 기록하여 성능 문제를 피할 수 있습니다.</p>\n<br />\n<ul>\n<li><strong>스트림 처리</strong></li>\n</ul>\n<p>짧은 간격으로 차례대로 데이터를 꺼내서 처리하는 것을 <em>스트림 처리</em>라고 합니다.</p>\n<br />\n<p>메시지 브로커로 부터 소비자에게로 초당 데이터를 보내는 것을 스트림 처리의 예시라고 볼 수 있죠.</p>\n<br />\n<ul>\n<li><strong>메시지 라우팅</strong></li>\n</ul>\n<p>메시지가 복사되어 데이터를 여러 분기시킬 수 있는 것을 말합니다.</p>\n<br />\n<p>일부의 데이터는 실시간으로, 일부의 데이터는 데이터 분석을 위한 분산 스토리지로 분기 시켜 보낼 수 있습니다.</p>\n<br />\n<h3 id=\"메시지-배송을-위한-세-가지-설계-방식\" style=\"position:relative;\"><a href=\"#%EB%A9%94%EC%8B%9C%EC%A7%80-%EB%B0%B0%EC%86%A1%EC%9D%84-%EC%9C%84%ED%95%9C-%EC%84%B8-%EA%B0%80%EC%A7%80-%EC%84%A4%EA%B3%84-%EB%B0%A9%EC%8B%9D\" aria-label=\"메시지 배송을 위한 세 가지 설계 방식 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>메시지 배송을 위한 세 가지 설계 방식</h3>\n<br />\n<p>성능 문제 외 중복이나 누락 등의 <strong>신뢰성</strong> 문제가 있습니다.</p>\n<br />\n<p>이런 경우 대부분 다음 중 하나의 설계 방식을 보장하도록 합니다.</p>\n<br />\n<ol>\n<li>at most once</li>\n</ol>\n<p>메시지는 한번만 전송. 하지만 전송 도중 실패할 수 있음(결손)</p>\n<br />\n<ol start=\"2\">\n<li>exactly once</li>\n</ol>\n<p>메시지는 손실되거나 중복 없이 한 번만 전달.</p>\n<br />\n<ol start=\"3\">\n<li>at least once</li>\n</ol>\n<p>메시지는 확실히 전달되나, 여러 번 전달될 수 있음(중복)</p>\n<br />\n<p>얼핏 보기에는 exactly once가 효율적으로 보이나, 이는 내부적으로 <strong>코디네이터</strong>라는 중계자를 사용합니다.</p>\n<br />\n<p>이 코디네이터를 통해서 exactly once를 실행하면 신뢰성은 어느정도 보장되나, 시간 지연 및 코디네이터에 대한 의존성이 높아져 이를 도입하지 않습니다.</p>\n<br />\n<p>오히려 at least once를 사용해 중복 제거는 사용자에게 맡기는 구조를 사용합니다.\r\n<br /></p>\n<p>특히 TCP/IP의 경우 TCP 패킷에 그것을 식별하는 시퀀스 번호가 포함되어 있어 중복 제거를 실행할 수 있습니다.</p>\n<br />\n<ul>\n<li>Apache Flume : at least once 보장</li>\n<li>Apache Kafka : at least once를 보장</li>\n<li>Logstash : at least once를 보장</li>\n<li>Fluentd : 옵션으로 at least once를 보장</li>\n</ul>\n<br />\n<h3 id=\"중복-제거\" style=\"position:relative;\"><a href=\"#%EC%A4%91%EB%B3%B5-%EC%A0%9C%EA%B1%B0\" aria-label=\"중복 제거 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>중복 제거</h3>\n<br />\n<p>TCP에서와 같이 모든 메시지에 시퀀스 번호를 붙히기엔 성능 향상 면에서 불필요합니다.</p>\n<br />\n<p>따라서 그 대안으로 여러 방법이 사용됩니다.</p>\n<br />\n<ol>\n<li><strong>오프셋을 이용한 중복 제거</strong></li>\n</ol>\n<br />\n<p>이 경우는 데이터의 파일 시작 위치 정보를 담은 작은 메시지를 담아서 보냅니다.</p>\n<br />\n<p>벌크 형 데이터 전송에는 이러한 방법을 사용하나, 스트리밍 형식의 메시지 배송에서는 거의 사용하지 않습니다.</p>\n<br />\n<ol start=\"2\">\n<li>고유 ID에 의한 중복 제거</li>\n</ol>\n<br />\n<p>모든 메시지에 UUID 등의 고유 ID를 지정해주는 방법입니다. 이 경우에는 중복의 가능성을 완전히 제거하지는 못하나, 최근에 받은 메시지의 중복도를 낮춤으로써 신뢰성을 향상시킵니다.(예를 들어 최근 1시간만 기억)</p>\n<br />\n<p>신뢰성 높은 메시지 전송을 위해서는 중간 경로를 모두 at least once로 통일한 후, 고유 ID를 통해 중복을 제거해야 합니다.</p>\n<br />\n<p>만약 중간 경로에 at most once가 존재한다면 결손의 가능성도 있기 때문입니다.</p>\n<br />\n<h4 id=\"고유-id를-통한-중간-제거의-방법\" style=\"position:relative;\"><a href=\"#%EA%B3%A0%EC%9C%A0-id%EB%A5%BC-%ED%86%B5%ED%95%9C-%EC%A4%91%EA%B0%84-%EC%A0%9C%EA%B1%B0%EC%9D%98-%EB%B0%A9%EB%B2%95\" aria-label=\"고유 id를 통한 중간 제거의 방법 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>고유 ID를 통한 중간 제거의 방법</h4>\n<br />\n<ol>\n<li><strong>NoSQL 데이터베이스를 이용</strong></li>\n</ol>\n<p>Cassandra나 Elasticsearch 등은 특성상 데이터를 쓸 때 고유 ID를 지정하고 동일한 ID는 덮어써 중복을 없앱니다.</p>\n<br />\n<ol start=\"2\">\n<li><strong>SQL로 중복을 제거</strong></li>\n</ol>\n<p>보내온 데이터를 객체 스토리지에 저장한 후, 나중에 읽는 단계에서 중복을 제거하는 겁니다.</p>\n<br />\n<p>이는 대규모 데이터 처리이므로 메모리에서 처리하는 것이 불가능하며, Hive와 같은 배치형 쿼리 엔진을 통해 진행해야 합니다.</p>\n<br />\n<div class=\"gatsby-highlight\" data-language=\"sql\"><pre class=\"language-sql\"><code class=\"language-sql\"><span class=\"token comment\">// DISTINCT를 통한 중복 제거</span>\r\n<span class=\"token keyword\">SELECT</span> <span class=\"token keyword\">DISTINCT</span> unique_id<span class=\"token punctuation\">,</span> col1<span class=\"token punctuation\">,</span> col2<span class=\"token punctuation\">,</span> <span class=\"token punctuation\">.</span><span class=\"token punctuation\">.</span><span class=\"token punctuation\">.</span> <span class=\"token keyword\">FROM</span> <span class=\"token keyword\">table</span><span class=\"token punctuation\">;</span>\r\n\r\n<span class=\"token comment\">// GROUP BY를 통한 중복 제거</span>\r\n<span class=\"token keyword\">SELECT</span> <span class=\"token function\">max</span><span class=\"token punctuation\">(</span>col1<span class=\"token punctuation\">)</span> col1<span class=\"token punctuation\">,</span> <span class=\"token function\">max</span><span class=\"token punctuation\">(</span>col2<span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> <span class=\"token punctuation\">.</span><span class=\"token punctuation\">.</span><span class=\"token punctuation\">.</span> <span class=\"token keyword\">FROM</span> <span class=\"token keyword\">table</span> <span class=\"token keyword\">GROUP</span> <span class=\"token keyword\">BY</span> unique_id<span class=\"token punctuation\">;</span></code></pre></div>\n<br />\n<p>빅 데이터 시스템은 매우 높은 성능을 요구하기에 아주 작은 중복은 무시하는 경향이 있습니다.</p>\n<br />\n<p>그렇기에 멱등한 조작에 유의하여 중복이 있어도 문제가 되지 않는 시스템을 설계하는 것을 추천합니다.</p>\n<br />\n<p>따라서 신뢰성이 중시되는 경우에는 되도록 스트리밍 형식의 메시지 전송을 피하고, 벌크 형의 데이터 전송을 하여 중복/결손을 피해야합니다.</p>\n<br />\n<hr>\n<h3 id=\"시계열-데이터의-최적화\" style=\"position:relative;\"><a href=\"#%EC%8B%9C%EA%B3%84%EC%97%B4-%EB%8D%B0%EC%9D%B4%ED%84%B0%EC%9D%98-%EC%B5%9C%EC%A0%81%ED%99%94\" aria-label=\"시계열 데이터의 최적화 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>시계열 데이터의 최적화</h3>\n<br />\n<ul>\n<li><strong>이벤트 시간</strong></li>\n</ul>\n<p>클라이언트 상에서 메시지가 생성된 시간</p>\n<ul>\n<li><strong>프로세스 시간</strong></li>\n</ul>\n<p>서버가 처리하는 시간</p>\n<br />\n<p>분석의 대상이 되는 것은 이 이벤트 시간입니다.</p>\n<br />\n<p>이벤트 시간과 프로세스 시간은 어느정도 차이가 존재합니다.</p>\n<br />\n<p>이벤트가 발생했다고 해서 그 날 바로 즉시 데이터가 배송되어 도착하는 것은 아닙니다.</p>\n<br />\n<p>일련의 처리과정을 거치고 도달한 시간인 프로세스 시간과 차이가 있죠.</p>\n<br />\n<p>즉, 이러한 문제를 해결하기 위해서 <strong>분산 스토리지에 저장하는 경우 프로세스 시간을 기준</strong>으로 구분합니다.</p>\n<br />\n<p>프로세스 시간동안 수집한 특정 이벤트 시간을 분석해야 하는 경우를 생각해봅시다.</p>\n<br />\n<p>그러기 위해서는 각 프로세스 시간 동안 존재하는 특정 이벤트 시간을 가져와야하죠.</p>\n<br />\n<p>원하는 특정 이벤트 시간은 따로 정렬되어 있지 않기에 우리는 각 프로세스 시간 파일을 뒤져가며 이벤트 시간을 찾아야 합니다.</p>\n<br />\n<p>이렇게 <strong>다수의 파일을 모두 검색하는 쿼리</strong>를 <strong>풀 스캔</strong>이라고 합니다.</p>\n<br />\n<p>굉장히 비효율적인 방법입니다. 이벤트 시간에 의한 집계를 효율적으로 바꿀 필요가 있습니다.</p>\n<br />\n<h3 id=\"시계열-인덱스\" style=\"position:relative;\"><a href=\"#%EC%8B%9C%EA%B3%84%EC%97%B4-%EC%9D%B8%EB%8D%B1%EC%8A%A4\" aria-label=\"시계열 인덱스 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>시계열 인덱스</h3>\n<br />\n<p>이벤트 시간 취급을 효율화하기 위해 데이터를 정렬하는 것을 고려할때,</p>\n<p>이벤트 시간에 대해 인덱스 만드는 방법이 있습니다.</p>\n<br />\n<p>이 방법은 Cassandra(NoSQL)와 같은 시계열 인덱스에 대응하는 <strong>분산 데이터베이스</strong>를 사용하면 이벤트 시간으로 인덱스된 테이블을 얻을 수 있습니다.</p>\n<br />\n<p>일반적으로 Cassandra와 같은 NoSQL은 장기간 집계에 최적화 되있지 않습니다.</p>\n<br />\n<p>짧은 범위라면 빠르게 집계할 수 있으나, 열 지향 스토리지를 지속적으로 만들어 집계하는 것에 못미칩니다.</p>\n<br />\n<p>헷갈리면 안되는 것이 일반적인 분산 데이터베이스는 여러 곳으로 분산된 데이터베이스를 하나의 가상 시스템처럼 사용할 수 있는 데이터베이스를 의미합니다. NoSQL이라고 부르는 데이터베이스들은 분산 데이터베이스로 사용가능합니다.</p>\n<br />\n<h3 id=\"조건절-푸쉬다운\" style=\"position:relative;\"><a href=\"#%EC%A1%B0%EA%B1%B4%EC%A0%88-%ED%91%B8%EC%89%AC%EB%8B%A4%EC%9A%B4\" aria-label=\"조건절 푸쉬다운 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>조건절 푸쉬다운</h3>\n<br />\n<p>도착한 데이터를 배치 처리로 변환하는 것을 고려해봅시다.</p>\n<br />\n<p>우선 이벤트 시간으로 데이터를 정렬해줍니다.(RDB)</p>\n<br />\n<p>이후, 열 지향 스토리지로 변환하도록 합니다. 그렇게 되면 <em>칼럼 단위의 통계 정보</em>를 이용해 최적화가 이루어집니다.</p>\n<br />\n<p>즉, 원하는 이벤트 시간의 값이 어디있는지 알 수 있다는 겁니다. 정렬되어 있다는 이점을 이용해 해당 프로세스 시간 기간 당 이벤트 시간을 모두 탐색하지 않더라도 이벤트 시간을 찾을 수 있습니다.</p>\n<br />\n<p><strong>칼럼 단위의 통계 정보를 이용해 최소한의 데이터만을 읽는 최적화</strong>를 <strong>조건절 푸쉬다운</strong>이라고 합니다.</p>\n<br />\n<h3 id=\"이벤트-시간에-의한-분할\" style=\"position:relative;\"><a href=\"#%EC%9D%B4%EB%B2%A4%ED%8A%B8-%EC%8B%9C%EA%B0%84%EC%97%90-%EC%9D%98%ED%95%9C-%EB%B6%84%ED%95%A0\" aria-label=\"이벤트 시간에 의한 분할 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>이벤트 시간에 의한 분할</h3>\n<br />\n<p>데이터 검색을 더욱 효과적으로 하기 위해서는 앞서 진행한 조건절 푸쉬다운에 테이블 파이셔닝의 개념을 도입하면 됩니다.</p>\n<br />\n<p>앞서 분산 처리 시스템에서 팩트 테이블을 생성하는 때에 테이블 파티셔닝을 통해서 결손 및 중복 문제를 해결했음을 기억해봅시다.</p>\n<br />\n<p>마찬가지로 이벤트 시간을 기준으로 테이블 파티셔닝을 진행하여 분할합니다. 이때 생성된 테이블을 <strong>시계열 테이블</strong>이라고 합니다.</p>\n<br />\n<p>다만, 시간이 지날 수록 분산 스토리지에 대량의 작은 파일이 만들어져 쿼리 성능은 점차 악화됩니다. 작은 데이터를 효율적으로 사용할 수 있는 분산 데이터베이스를 사용하거나 버리는 아이디어가 필요합니다.</p>\n<br />\n<h3 id=\"데이터-마트를-이벤트-시간으로-정렬\" style=\"position:relative;\"><a href=\"#%EB%8D%B0%EC%9D%B4%ED%84%B0-%EB%A7%88%ED%8A%B8%EB%A5%BC-%EC%9D%B4%EB%B2%A4%ED%8A%B8-%EC%8B%9C%EA%B0%84%EC%9C%BC%EB%A1%9C-%EC%A0%95%EB%A0%AC\" aria-label=\"데이터 마트를 이벤트 시간으로 정렬 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>데이터 마트를 이벤트 시간으로 정렬</h3>\n<br />\n<p>지금까지는 데이터 마트로 이동하기 이전, 집계 성능을 최적화 하기 위한 데이터 수집 방법에 대해 알아보았습니다.(데이터 수집부터 데이터 레이크까지)</p>\n<br />\n<p>하지만, 데이터 수집 단계에서 이벤트 시간을 따로 따지지 않고 프로세스 시간만을 이용하여 저장한 후, 데이터 마트를 만드는 과정에서 이벤트 시간에 대해 정렬을 합니다.</p>\n<br />\n<p>즉, 테이블 파티셔닝을 하지 않고, 조건절 푸쉬다운 상태에서 그대로 데이터 마트로 이동하여 정렬을 합니다.</p>\n<br />\n<p>그러면 파일이 조각나지않고, 최적의 상태를 유지합니다.</p>\n<br />\n<h3 id=\"nosql-데이터베이스에-의한-데이터-활용\" style=\"position:relative;\"><a href=\"#nosql-%EB%8D%B0%EC%9D%B4%ED%84%B0%EB%B2%A0%EC%9D%B4%EC%8A%A4%EC%97%90-%EC%9D%98%ED%95%9C-%EB%8D%B0%EC%9D%B4%ED%84%B0-%ED%99%9C%EC%9A%A9\" aria-label=\"nosql 데이터베이스에 의한 데이터 활용 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>NoSQL 데이터베이스에 의한 데이터 활용</h3>\n<br />\n<p>분산 데이터베이스로써 사용할 수 있는 스토리지는 객체 스토리지 및 NoSQL이 있습니다.</p>\n<br />\n<p>객체 스토리지는 임의의 덩어리 파일을 저장할 수 있는 데이터베이스라고 배웠습니다.</p>\n<br />\n<p>하지만 객체 스토리지를 분산 데이터베이스로 사용하기에는 어느정도 단점이 존재합니다.</p>\n<br />\n<ol>\n<li>객체 스토리지 상의 파일은 교체가 어렵습니다.</li>\n</ol>\n<p>일단 써놓으면 그것을 통째로 바꾸는 방법밖에 없습니다.</p>\n<br />\n<ol start=\"2\">\n<li>객체 스토리지에 저장된 데이터를 집계하기까지 시간이 걸립니다.</li>\n</ol>\n<p>즉 실시간 집계(가령 시계열 DB를 만드는 경우)를 하는 때에 열 지향 스토리지로 만들어 집계하기 까지 시간이 너무 걸린다는 말입니다.</p>\n<br />\n<p>이를 위해 <strong>특정 용도에 최적화된 데이터 저장소</strong>를 일컬어 <strong>NoSQL 데이터베이스</strong>를 사용합니다.</p>\n<br />\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 720px; \"\n    >\n      <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 62.77777777777778%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAANCAYAAACpUE5eAAAACXBIWXMAAA7DAAAOwwHHb6hkAAABaklEQVQ4y41Sa2+DMAzk///LbmqhLUkgrwKB3nRejVLWD7NkJbHPr3MaAHg+n6L1/T+q+FqaI8g5i8E5xBjR9z3GYYD3AeM4YhgGxBTlvpTypwFJiIPQsa0rtm2TeykFKSXxqU1PwR9im3mepdq6rhI8TfPupI826rIsgmEy1Xma5SyveOmQQSEEXLtOzmma8Hg8ZCwCvR/Rdp1QkHOGcw7fX184ny84X36V1LCgJCSI3JxOJ1yvN4QYJBGTMjnH9d7LSRuVbxZ35DRG8e0J2SoNBFDZsYqOxgI1+cQzEWPZDJPtSzmuvX7zvlRLqX1MxgmO+EbGyFkq8k4K2BWr8q3d6Fg6EW3G2J2KvUOCgvdoL61wo0vRBXEp1hrknKALJO5+74VzY40kLa9/2SjpXdvJBhmgXyamJB1rpzwZqB3Tx5PYNw6VDyWfwje36KwV4u+3mySi5JRhjJFG+L3eOMQHOS6qtn3y1fYfwOr5AUpFafIAAAAASUVORK5CYII='); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"흐름.png\"\n        title=\"흐름.png\"\n        src=\"/static/eadd609bb3f01966b6c0fcb50b8a7e04/37523/%ED%9D%90%EB%A6%84.png\"\n        srcset=\"/static/eadd609bb3f01966b6c0fcb50b8a7e04/e9ff0/%ED%9D%90%EB%A6%84.png 180w,\n/static/eadd609bb3f01966b6c0fcb50b8a7e04/f21e7/%ED%9D%90%EB%A6%84.png 360w,\n/static/eadd609bb3f01966b6c0fcb50b8a7e04/37523/%ED%9D%90%EB%A6%84.png 720w,\n/static/eadd609bb3f01966b6c0fcb50b8a7e04/8bd7c/%ED%9D%90%EB%A6%84.png 845w\"\n        sizes=\"(max-width: 720px) 100vw, 720px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n        decoding=\"async\"\n      />\n    </span></p>\n<p>정리해서 흐름을 한번 살펴 봅시다.</p>\n<br />\n<p>우선 스트림 처리의 경우 시계열 DB를 만들어 바로 활용할 수 있는 구조입니다.(이벤트 시간으로 구성된 파티션 집합)\r\n여기서 쿼리엔진을 통해 사용할 수 있는 것이죠.</p>\n<br />\n<p>우리는 분산 스토리지로 객체 스토리지를 사용하여 하둡 및 스파크 등 분산 처리 시스템을 통해 열지향 DB로 바꾼 후, 집계를 실시했습니다.</p>\n<br />\n<p>하지만, 짧은 범위의 빠른 집계 및 고속 검색을 위해서는 이런 객체 스토리지를 사용하는 것보다 NoSQL을 사용함으로써, 용도에 맞게 바로 기록하고 활용할 수 있다는 겁니다.</p>\n<br />\n<p>NoSQL의 예로 <em>분산 KVS</em>, <em>와이드 칼럼 스토어</em>, <em>도큐먼트 스토어</em>, <em>검색 엔진</em> 등이 있습니다.</p>\n<br />\n<ul>\n<li>분산 KVS : 디스크 쓰기 속도를 높임</li>\n<li>와이드 칼럼 스토어 : 구조화 데이터를 분석해서 저장함</li>\n<li>도큐먼트 스토어 : 스키마리스 데이터 관리</li>\n<li>검색 엔진 : 키워드 검색으로 데이터 검색</li>\n</ul>\n<hr>\n<h3 id=\"분산-kvs\" style=\"position:relative;\"><a href=\"#%EB%B6%84%EC%82%B0-kvs\" aria-label=\"분산 kvs permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>분산 KVS</h3>\n<p>모든 데이터를 키값 쌍으로 저장하도록 설계된 데이터 저장소를 말합니다.</p>\n<br />\n<p>객체 스토리지도 넓은 의미에서는 분산 KVS의 일종이나 여기서는 좀더 ‘작은 데이터’를 가정합니다.</p>\n<br />\n<p>구체적으로 몇 kb정도의 데이터를 초당 수만 번 읽고 쓰는 정도입니다.</p>\n<br />\n<p>분산 KVS는 모든 데이터에 <strong>고유의 키</strong>를 지정한 후, 부하 분산을 실시합니다.</p>\n<br />\n<p>아키텍처에 대한 예시는 다음과 같습니다.</p>\n<br />\n<ol>\n<li>마스터/슬레이브 형</li>\n</ol>\n<p>1대의 마스터가 전체를 관리합니다. 마스터가 중지하면 아무도 데이터를 읽고 쓸 수 없습니다.</p>\n<br />\n<ol start=\"2\">\n<li>p2p형 시스템</li>\n</ol>\n<p>모든 노드가 대등한 관계이므로 어떤 노드에 연결해도 데이터를 읽을 수 있습니다.</p>\n<br />\n<ul>\n<li><strong>Amazon DynamoDB</strong></li>\n</ul>\n<br />\n<p>항상 안정된 읽기 쓰기 성능을 제공하도록 디자인된 NoSQL 데이터베이스로 하나 또는 두 개의 키에 연결하는 형태로 임의의 스키마리스 데이터를 저장할 수 있습니다.</p>\n<br />\n<p>DynamoDB는 P2P형의 분산 아키텍처를 가지고 있습니다. DynamoDB에서는 사용자 수에 따라 노드의 수를 조절할 수 있어 성능 향상에 있어 유리합니다.</p>\n<br />\n<p>데이터 분석 방법은 다음과 가가습니다.</p>\n<br />\n<ol>\n<li>Amazon EMR과 결합하여 Hive에 의한 배치 처리를 진행합니다.</li>\n</ol>\n<br />\n<ol start=\"2\">\n<li>Amazon Redshift와 결합하여 데이터 웨어하우스에 데이터를 저장합니다.</li>\n</ol>\n<br />\n<ol start=\"3\">\n<li>DynamoDB 고유 기능인 Dynamo Streams를 통해 외부로 실시간 스트림 처리가 가능합니다.</li>\n</ol>\n<br />\n<h3 id=\"와이드-칼럼-스토어\" style=\"position:relative;\"><a href=\"#%EC%99%80%EC%9D%B4%EB%93%9C-%EC%B9%BC%EB%9F%BC-%EC%8A%A4%ED%86%A0%EC%96%B4\" aria-label=\"와이드 칼럼 스토어 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>와이드 칼럼 스토어</h3>\n<br />\n<p>분산 KVS에서 발전시켜 2개 이상의 임의의 키에 데이터를 저장할 수 있도록 한 것이 <strong>와이드 칼럼 스토어</strong>입니다.</p>\n<br />\n<p>Google Cloud Bigtable, Apache Hbase, Apache Cassandra 가 대표적입니다.</p>\n<br />\n<p>내부적으로는 행만이 아니라 칼럼도 계속 증가합니다.</p>\n<br />\n<p>즉, 하나의 키에 대해서 여러개의 value를 확장시킬 수 있다는 뜻이 됩니다.</p>\n<br />\n<ul>\n<li><strong>Cassandra</strong></li>\n</ul>\n<br />\n<p>CQL이라는 쿼리 언어를 통해서 구조화 데이터를 취급할 수 있습니다.</p>\n<br />\n<p>p2p 형의 분산 아키텍처를 가지고 있습니다. 또한 거대한 데이터 테이블을 복합키를 이용해 관리합니다.</p>\n<br />\n<p>와이드 칼럼 스토어는 데이터 집계에 있어 적합하지 않습니다.</p>\n<br />\n<p>집계를 위해서는 분산 처리 시스템을 거쳐야 합니다. Hive, Presto, Spark등의 쿼리 엔진은 이에 대응하고 있습니다.</p>\n<br />\n<h3 id=\"도큐먼트-스토어\" style=\"position:relative;\"><a href=\"#%EB%8F%84%ED%81%90%EB%A8%BC%ED%8A%B8-%EC%8A%A4%ED%86%A0%EC%96%B4\" aria-label=\"도큐먼트 스토어 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>도큐먼트 스토어</h3>\n<br />\n<p>도큐먼트 스토어는 <strong>성능 향상</strong>의 목표 보단 <strong>데이터 처리의 유연성</strong>을 목적으로 합니다.</p>\n<br />\n<p>구체적으로는 스키마리스 데이터를 그대로 저장하고 쿼리를 실행할 수 있다는 것이죠.</p>\n<br />\n<p>물론 간단한 KVS의 경우에도 JSON 텍스트로 저장할 수 있으나 복잡한 쿼리를 실행할 수는 없습니다.</p>\n<br />\n<p>도큐먼트 스토어의 장점은 스키마를 정하지 않고 데이터를 처리할 수 있습니다.</p>\n<br />\n<ul>\n<li><strong>MongoDB</strong></li>\n</ul>\n<br />\n<p>MongoDB는 오픈 소스의 분산형 도큐먼트 스토어로 자바스크립트와 같은 프로그래밍 언어로 데이터를 읽고 쓸 수 있습니다.</p>\n<br />\n<p>간편함 덕분에 그 인기가 높습니다.</p>\n<br />\n<p>MongoDB도 여러 노드에 데이터를 분산할 수 있으나, 그 자체는 역시 대량의 데이터를 집계하는데 적합하지 않습니다.</p>\n<br />\n<h3 id=\"검색-엔진\" style=\"position:relative;\"><a href=\"#%EA%B2%80%EC%83%89-%EC%97%94%EC%A7%84\" aria-label=\"검색 엔진 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>검색 엔진</h3>\n<br />\n<p>NoSQL 데이터베이스와는 조금 성격이 다르지만, 저장된 데이터를 쿼리로 찾아낸다는 점에서 유사한 부분이 많고, 텍스트 데이터 및 스키마리스 데이터를 집계하는데 자주 사용됩니다.</p>\n<br />\n<p>특징은 텍스트 데이터를 전문 탐색하기 위해 역 색인을 만든다는 것입니다.</p>\n<br />\n<blockquote>\n<p>역 색인 : 텍스트에 포함된 단어를 분해하고 어떤 단어가 어떤 레코드에 포함되어 있는가 하는 인덱스를 먼저 만들어 검색을 고속화</p>\n</blockquote>\n<br />\n<p>대부분의 NoSQL은 성능 향상을 위해 색인 작성을 제한하는 경우가 많으나, 대조적으로 검색 엔진은 색인을 만듦으로써 데이터를 찾는 것에 특화되어 있습니다.</p>\n<br />\n<p>즉, 검색 엔진은 데이터 축적보단 실시간 집계 시스템의 일부로 이용합니다.</p>\n<br />\n<p>흐름에서 보았던 스트림 데이터 수집 이후 메시지 브로커를 통해 분산 스토리지로 가서 분산 처리 시스템을 거친 후, 데이터 마트를 만드는 것이 아닌 <strong>메시지 브로커</strong>에서 바로 <strong>검색 엔진</strong>으로 이동하여 실시간성이 높은 검색 도구를 만드는데 사용됩니다.</p>\n<br />\n<ul>\n<li><strong>Elasticssearch</strong></li>\n</ul>\n<br />\n<p>오픈 소스의 검섹 엔진으로써 인기가 많은 것은 Elasticssearch입니다.</p>\n<br />\n<p>로그 수집 소프트웨어인 <em>Logstash</em>, 시각화 소프트웨어인 <em>Kibana</em>와 함께 ELK 스택 또는 Elastic 스택으로 자주 이용됩니다.</p>\n<br />\n<p>Elasticsearch는 임의의 JSON 데이터를 저장할 수 있어 도큐먼트 스토어와 비슷하나 아무것도 지정하지 않으면 모든 필드에 색인을 만듭니다.</p>\n<br />\n<p>텍스트 데이터에서는 역 색인을 구축하기에 쓰기에 부하가 크고, 필요에 따라 색인을 무효화 시키기 위해 색인을 무효화 합니다.</p>\n<br />\n<p>자체 쿼리 언어에 의한 고급 집계 기능을 가지고 있습니다. 열 지향 스토리지에 대응하여 데이터 집계에 힘을 더해줍니다.</p>\n<br />\n<p>다만 표준 쿼리 언어가 복잡해서 Kibana와 같은 프론트엔드를 사용하거나 프로그램 안에서 호출합니다.</p>\n<br />\n<ul>\n<li><strong>Splunk</strong></li>\n</ul>\n<br />\n<p>오픈 소스는 아니지만 상용 검섹 엔진 Splunk도 텍스트 데이터를 집계하기 위한 도구로 알려져 있습니다.</p>\n<br />\n<p>자신하는 분야는 비정형 데이터, 즉 스키마리스 데이터/비구조화 데이터입니다.</p>\n<br />\n<p>특징은 검색할 때마다 데이터가 구조화 되어서 테이블을 만들 수 있다는 것입니다.</p>\n<br />\n<h3 id=\"정리\" style=\"position:relative;\"><a href=\"#%EC%A0%95%EB%A6%AC\" aria-label=\"정리 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>정리</h3>\n<br />\n<p>데이터를 모아서 분산 스토리지에 저장하기 까지의 데이터 수집의 흐름을 알아보았습니다.</p>\n<br />\n<p>집계 효율을 고려했을 때, 스트리밍 형은 배치 형에 비해 집계 효율이 떨어집니다.</p>\n<br />\n<p>따라서 메세지 배송 방식을 통해 메시지 브로커를 도입하여 분산 스토리지에 쓰는 속도를 안정화 했으며 경로를 라우팅하여 데이터를 스트리밍 처리 혹은 배치 처리 모두 사용할 수 있게 되었습니다.</p>\n<br />\n<p>전자의 경우 실시간 집계에 뛰어난 시계열 DB로 바로 만듭니다. 데이터 마트를 만드는 과정에서도 시계열 DB를 만들기도 합니다.</p>\n<br />\n<p>후자의 경우 대량 데이터 집계를 할 때 주로 배치처리를 함으로 Hive와 같은 쿼리 엔진으로 열 지향 DB로 만들어 줍니다.</p>\n<br />\n<p>시계열 인덱스 사용, 조건절 푸쉬 다운(정렬 후 열 지향으로 풀 스캔 피하기), 테이블 파티셔닝, 이벤트 시간에 대한 정렬을 데이터 마트 만들 때 실시하는 등으로 스트림 처리를 최적화합니다.</p>\n<br />\n<p>메시지 전송에서는 중복과 누락의 가능성이 있기에 일반적으로 at least once를 통해 중복을 어는 정도 허용한 후, 나중에 중복 데이터를 제거합니다.</p>\n<br />\n<p>기본적으로 Amazon S3, Hadoop HDFS와 같은 객체 스토리지를 분산 스토리지로 사용하나, 특정 용도에 최적화된 NoSQL을 사용하기도 합니다.</p>\n<br />\n<p>NoSQL 데이터베이스와 같은 분산 스토리지에 데이터를 쓰는 경우 읽기 및 쓰기 성능은 우수하나, 대량의 데이터를 집계하기에는 쿼리 엔진과 연결하여 애드 훅 분석을 하거나 장기적인 분석을 위한 데이터 웨어하우스를 구축해야 합니다.</p>\n<br />\n<p>검색 엔진의 경우 스트림 처리 이후 검색 엔진에서 실시간 집계 및 검색 도구로 사용될 수 있습니다.</p>\n<br />","excerpt":"제 4장. 빅데이터의 축적 객체 스토리지와 데이터 수집 빅데이터의 경우 확장성이 높은 분산 스토리지에 데이터 수집/저장합니다. 우선 기본이 되는 것은 객체 스토리지입니다. 대표적으로 Hadoop의 HDFS, 클라우드 서비스의 Amazon S3가 유명합니다. 이러한 객체 스토리지는 다수의 컴퓨터를 사용해 파일을 여러 디스크에 복사하여 저장합니다. 즉 중복화 및 분산/저장을 실시하나 소규모 데이터에 대해서는 통신오버헤드가 생겨 적합하지는 않죠. 객체 스토리지(분산 스토리지)안에 데이터를 기록/수집하는 것은 어느정도 노력이 필요합니다. 너무 작은 데이터는 모아서 기록하고, 너무 큰 데이터는 분할해서 기록하는 것이 집계 효율을 올리고, 문제를 예방할 수 있습니다. 데이터 수집 수집한 데이터를 가공하여 집계 효율이 좋은 분산 스토리지를 만드는 일련의 프로세스 벌크 형의 데이터 전송 데이터 전송 구조는 벌크 형과 스트리밍 형으로 나뉩니다. 먼저 벌크 형의 데이터 전송 구조는 ETL 서버 설치…","frontmatter":{"date":"February 16, 2023","title":"빅 데이터를 지탱하는 기술 책 리뷰 - (3)","categories":"Engineer","author":"DEVEL","emoji":"🦊"},"fields":{"slug":"/data-engineer-4/"}},"next":{"id":"8946dc13-6971-5972-8900-d850c5b3b049","html":"<h2 id=\"제-3장-빅데이터의-분산처리\" style=\"position:relative;\"><a href=\"#%EC%A0%9C-3%EC%9E%A5-%EB%B9%85%EB%8D%B0%EC%9D%B4%ED%84%B0%EC%9D%98-%EB%B6%84%EC%82%B0%EC%B2%98%EB%A6%AC\" aria-label=\"제 3장 빅데이터의 분산처리 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>제 3장. 빅데이터의 분산처리</h2>\n<br />\n<ul>\n<li><strong>스키마</strong></li>\n</ul>\n<p>테이블의 칼럼 명과 데이터형, 테이블 간의 관계 등</p>\n<ul>\n<li><strong>구조화된 데이터</strong></li>\n</ul>\n<p>스키마가 명확하게 정의된 데이터</p>\n<ul>\n<li><strong>비구조화 데이터</strong></li>\n</ul>\n<p>스키마가 없는 데이터</p>\n<ul>\n<li><strong>데이터 레이크</strong></li>\n</ul>\n<p>비구조화 데이터를 분산 스토리지에 저장하고 그것을 분산 시스템에서 처리하는 것</p>\n<ul>\n<li><strong>스키마리스 데이터</strong></li>\n</ul>\n<p>CSV, JSON, XML 등의 데이터와 같이 서식은 정해져 있지만, 칼럼 수나 데이터 형은 명확하지 않은 데이터</p>\n<br />\n<p>비구조화 데이터에서 구조화 데이터로 변환하고 일반적으로 구조화 데이터를 열 지향 스토리지로 저장합니다.</p>\n<br />\n<p>이를 위해 MPP 데이터베이스로 전송하거나 Hadoop 상에서 열 지향 스토리지 형식으로 변환합니다.</p>\n<br />\n<hr>\n<br />\n<p>Hadoop에서는 사용자가 직접 열 지향 스토리지 형식을 지정할 수 있고 그 특징이 다릅니다.</p>\n<br />\n<p>Apache ORC : 구조화 데이터를 위한 열 지향 스토리지</p>\n<p>Apache Parquet : 스키마리스 데이터 구조 처리 가능</p>\n<p>Hadoop : 단일 소프트웨어가 아닌 분산 시스템을 구성하는 다수의 소프트웨어로 이루어진 집합체</p>\n<br />\n<h3 id=\"hadoop의-구성요소\" style=\"position:relative;\"><a href=\"#hadoop%EC%9D%98-%EA%B5%AC%EC%84%B1%EC%9A%94%EC%86%8C\" aria-label=\"hadoop의 구성요소 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a><strong>Hadoop의 구성요소</strong></h3>\n<br />\n<p>분산 파일 시스템 : HDFS(Hadoop Distributed File System)</p>\n<p>리소스 관리자 : YARN(Yet Another Resource Negotiator)</p>\n<p>분산 데이터 처리의 기반 : MapReduce</p>\n<br />\n<ul>\n<li>HDFS, YARN의 역할</li>\n</ul>\n<p>데이터의 대부분은 분산 파일 시스템인 HDFS에 저장됩니다. CPU나 메모리 등의 계산 리소스는 리소스 매니저인 YARN에의해 관리되고 컨테이너라는 단위로 관리되죠.</p>\n<br />\n<h3 id=\"mapreduce\" style=\"position:relative;\"><a href=\"#mapreduce\" aria-label=\"mapreduce permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a><strong>MapReduce</strong></h3>\n<p>MapReduce도 YARN 상에서 동작하는 분산 애플리케이션 중 하나입니다.</p>\n<br />\n<p>데이터 처리를 담당하며 임의의 자바 프로그램을 실행하여 비구조화 데이터 처리에 뛰어납니다.</p>\n<br />\n<p>Apache Hive의 경우에는 MapReduce에 의존하는 쿼리 엔진입니다.(정확히는 쿼리를 쿼리를 MapReduce 프로그램으로 변환)</p>\n<br />\n<p>MapReduce는 대용량 데이터 배치처리에 적합합니다. 따라서 Hive도 배치 처리에 적합합니다.</p>\n<h3 id=\"hive-on-tez\" style=\"position:relative;\"><a href=\"#hive-on-tez\" aria-label=\"hive on tez permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Hive on Tez</h3>\n<p>Hive를 가속화하기 위한 노력으로 Apache Tez가 등장했습니다. 기존의 Hive의 경우 하나의 쿼리를 처리하는데 여러 스테이지를 나누어 처리했습니다.</p>\n<p>이는 가속화에 있어 어느정도 걸림돌이 되었고, Tez가 스테이지의 종료를 기다리지 않고 다음 스테이지로 먼저 처리된 데이터를 보낼 수 있게 됨으로써 이를 보완합니다.</p>\n<br />\n<ul>\n<li>Hive on Tez</li>\n<li>Hive on MR</li>\n</ul>\n<br />\n<h3 id=\"대화형-쿼리-엔진\" style=\"position:relative;\"><a href=\"#%EB%8C%80%ED%99%94%ED%98%95-%EC%BF%BC%EB%A6%AC-%EC%97%94%EC%A7%84\" aria-label=\"대화형 쿼리 엔진 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a><strong>대화형 쿼리 엔진</strong></h3>\n<p>앞서 말했듯이 대화형 쿼리 엔진에는 MPP 데이터베이스 아키텍처 기반이 있다고 했습니다. 물론 완벽한 압축의 역할은 못한다고 했지만요.</p>\n<p>하지만 여러 CPU를 사용하는 멀티스레드를 사용하여 오버헤드를 최대한 줄인다는 점에서 ‘분산’의 역할은 충실히 하고 있는 것이지요.</p>\n<p>대표적으로 Apache Implala(아파치 임팔라)와 Presto가 대표적입니다.</p>\n<p>즉, 이 과정에서 데이터 마트로 만드는데 MPP 데이터베이스보단 못하지만, Hadoop 환경에서 호환되어 사용되는 겁니다.</p>\n<br />\r\n<br />\n<h3 id=\"정리\" style=\"position:relative;\"><a href=\"#%EC%A0%95%EB%A6%AC\" aria-label=\"정리 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>정리</h3>\n<p>무거운 배치 처리에 있어서는 Hive 이용, 주로 비구조화 데이터를 구조화로 처리(데이터레이크와 데이터 마트 사이에서 비 구조화 데이터를 구조화 데이터로)</p>\n<br />\r\n구조화 데이터를 대화식 집계하기 위해 주로 Impala, Presto를 통해 지연을 줄임\r\n(데이터 마트로 만듬)\n<hr>\n<br />\n<h3 id=\"spark\" style=\"position:relative;\"><a href=\"#spark\" aria-label=\"spark permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a><strong>Spark</strong></h3>\n<p>Spark는 MapReduce를 대체하는 존재입니다. 즉, 분산 파일 시스템은 HDFS, 리소스 관리자는 YARN으로 사용할 수 있다는 것이죠.</p>\n<br />\n<p>Spark의 특징은 중간 데이터를 디스크에 쓰지 않고, 메모리에 보존합니다. 따라서 중간 데이터를 읽어버려도 입력 데이터로 다시 실행합니다.</p>\n<br />\n<hr>\n<br />\n<p>Hive에서 만든 각 테이블의 정보는 ‘Hive 메타 스토어’라는 특별한 데이터베이스에 저장됩니다. 즉, 여기에 비정규화 테이블 직전의 테이블인 디멘전 테이블과 팩트 테이블이 존재하는 것이지요.</p>\n<br />\n<p>펙트 테이블은 트랜잭션과 같이 시간과 같이 생성되는 데이터로 이루어진 테이블, 디멘전 테이블은 재 사용 가능한 데이터인 마스터 테이블로 이루어진 테이블이었습니다.(열 지향 or 행 지향)</p>\n<br />\n<p>이 두 테이블을 이용하여 우리는 비정규화 테이블을 작성해야 합니다.\r\n이때, Presto와 같은 대화형 쿼리 엔진을 이용할지, Hive 같은 배치형 쿼리 엔진을 사용해야 할 지는 생각에 따라 달라집니다.</p>\n<br />\n<p>우리는 시간이 걸리는 배치 처리의 경우이므로 Hive를 사용할 것입니다.\r\n하지만, 비정규화 테이블은 만드는 것은 오랜 시간이 걸리는 일이므로 쿼리를 개선하는 방법을 알아야합니다. 방법은 다음과 같습니다.</p>\n<br />\n<ol>\n<li>\n<p><strong>서브 쿼리 안에서 레코드 수 줄이기</strong></p>\n<p>기존의 팩트 테이블(“access_log”)과 디멘전 테이블(“user”)을 결합하고 WHERE로 조건을 부여하는 쿼리는 간단하지만 비효율적입니다.</p>\n<p>따라서 팩트 테이블을 작게 만들고 데이터를 집계하는 것이 시간 단축에 효율적입니다.</p>\n<div class=\"gatsby-highlight\" data-language=\"sql\"><pre class=\"language-sql\"><code class=\"language-sql\"><span class=\"token keyword\">SELECT</span> <span class=\"token punctuation\">.</span><span class=\"token punctuation\">.</span><span class=\"token punctuation\">.</span>\r\n<span class=\"token keyword\">FROM</span> <span class=\"token punctuation\">(</span>\r\n    <span class=\"token keyword\">SELECT</span> <span class=\"token operator\">*</span> access_log\r\n    <span class=\"token keyword\">WHERE</span> <span class=\"token keyword\">time</span> <span class=\"token operator\">>=</span> <span class=\"token keyword\">TIMESTAMP</span> <span class=\"token string\">'2017-01-01 00:00:00'</span>\r\n<span class=\"token punctuation\">)</span> a\r\n<span class=\"token keyword\">JOIN</span> users b <span class=\"token keyword\">ON</span> b<span class=\"token punctuation\">.</span>id <span class=\"token operator\">=</span> a<span class=\"token punctuation\">.</span>user_id\r\n<span class=\"token keyword\">WHERE</span> b<span class=\"token punctuation\">.</span>created_at <span class=\"token operator\">=</span> <span class=\"token string\">'2017-01-01'</span></code></pre></div>\n</li>\n</ol>\n<br />\n<br />\n<ol start=\"2\">\n<li><strong>데이터 편향 피하기</strong></li>\n</ol>\n<p>만약 분산 시스템에서 고유한 어떤 종류를 카운트한다고 하자. 그렇다면 중복이 없는 값을 세기 위해 데이터를 한 곳에 모아야 하기에 분산 처리가 어려울 것입니다.(select distinct…)</p>\n<br />\n<p>이 문제를 해결하기 위해 GROUP BY를 통해 분산처리를 실행해 줍니다. 하지만 이 또한 GROUP BY를 각각 한 단위 안에서(즉 한 CPU 안에서) 많은 중복값이 존재한다면 다른 처리 시간 보다 많은 시간이 걸릴 것입니다.</p>\n<br />\n<p>이를 예방하기 위해, 즉 데이터의 편향 문제를 해결하기 위해 모든 노드에 데이터가 균등하게 분산되도록 해야 합니다. 즉, 중복을 <strong>최초에 줄인</strong> 테이블에서 선택하는 것입니다!</p>\n<br />\n<div class=\"gatsby-highlight\" data-language=\"sql\"><pre class=\"language-sql\"><code class=\"language-sql\"><span class=\"token keyword\">SELECT</span> <span class=\"token keyword\">date</span><span class=\"token punctuation\">,</span> <span class=\"token function\">count</span><span class=\"token punctuation\">(</span><span class=\"token operator\">*</span><span class=\"token punctuation\">)</span> users\r\n<span class=\"token keyword\">FROM</span> <span class=\"token punctuation\">(</span>\r\n    <span class=\"token keyword\">SELECT</span> <span class=\"token keyword\">DISTINCT</span> <span class=\"token keyword\">date</span><span class=\"token punctuation\">,</span> user_id <span class=\"token keyword\">FROM</span> access_log\r\n<span class=\"token punctuation\">)</span> t\r\n<span class=\"token keyword\">GROUP</span> <span class=\"token keyword\">BY</span> <span class=\"token keyword\">date</span></code></pre></div>\n<br />\n<hr>\n<h3 id=\"대화형-쿼리-엔진-presto의-구조와-특징\" style=\"position:relative;\"><a href=\"#%EB%8C%80%ED%99%94%ED%98%95-%EC%BF%BC%EB%A6%AC-%EC%97%94%EC%A7%84-presto%EC%9D%98-%EA%B5%AC%EC%A1%B0%EC%99%80-%ED%8A%B9%EC%A7%95\" aria-label=\"대화형 쿼리 엔진 presto의 구조와 특징 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a><strong>대화형 쿼리 엔진 Presto의 구조와 특징</strong></h3>\n<br />\n<p>대화형 쿼리엔진  : 쿼리 실행의 지연을 감소시키는 것이 목적</p>\n<br />\n<ul>\n<li><strong>플러그인 가능한 스토리지</strong></li>\n</ul>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 720px; \"\n    >\n      <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 54.44444444444444%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAALCAYAAAB/Ca1DAAAACXBIWXMAAB2HAAAdhwGP5fFlAAABAUlEQVQoz42T2Y6DMAxF8/9f2tIBJglLWF0djy5CCHX6cJXE2MdLQljX1a6apslVSrFlWdy2bZvd+V4VzgeCAKWUrGkaF2fsgAX/Gojmeba+7+3n9XIwwGEYrOs6F3vB8b0mCXet7Ptu4zi6M3AqBf4bo+WUHYrw4TtgcYIyKKvaY34EaY4EF1SKJ0TYSYTfASRDXdcWY/SWWFFVVb5OpfxVWdful2JyeNu21vWdA4nTrIPmozaoIOdsz8fzuBQA2BC+VIIviTRj4hx4HbBa1hwVCCyl7Hv5IyrFdrTMRjo/H+3VHq0xAsDYJCo7x4X/3tX5kpBu9K6Q23f4CfzNn/IGO8lcuyK1wWYAAAAASUVORK5CYII='); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"Presto구조\"\n        title=\"Presto구조\"\n        src=\"/static/3802db66de6514ddeaef301b1c5ffcc5/37523/Presto%EA%B5%AC%EC%A1%B0.png\"\n        srcset=\"/static/3802db66de6514ddeaef301b1c5ffcc5/e9ff0/Presto%EA%B5%AC%EC%A1%B0.png 180w,\n/static/3802db66de6514ddeaef301b1c5ffcc5/f21e7/Presto%EA%B5%AC%EC%A1%B0.png 360w,\n/static/3802db66de6514ddeaef301b1c5ffcc5/37523/Presto%EA%B5%AC%EC%A1%B0.png 720w,\n/static/3802db66de6514ddeaef301b1c5ffcc5/302a4/Presto%EA%B5%AC%EC%A1%B0.png 1080w,\n/static/3802db66de6514ddeaef301b1c5ffcc5/07a9c/Presto%EA%B5%AC%EC%A1%B0.png 1440w,\n/static/3802db66de6514ddeaef301b1c5ffcc5/df438/Presto%EA%B5%AC%EC%A1%B0.png 1556w\"\n        sizes=\"(max-width: 720px) 100vw, 720px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n        decoding=\"async\"\n      />\n    </span></p>\n<p>Presto는 Hive와 마찬가지로 데이터 소스에서 직접 데이터를 읽어들입니다.(처음에 데이터를 가지고 있어야 하는 MPP 데이터베이스와는 상반)</p>\n<p>비구조화 데이터를 구조화 데이터로 만드는데 쓰일 수도 있으나 Hive보다 크게 뛰어나지 않습니다. 즉 구조화 데이터를 집계하는데 주 목적을 둡니다.</p>\n<br />\n<p>🔥 <strong>왜 안되는데?</strong></p>\n<br />\n<p>가령 텍스트 처리가 중심인 ETL프로세스 및 데이터 구조화는 대화형 쿼리엔진이 적합하지 않습니다.</p>\n<br />\n<p>빠르지만 적절한 용량으로 한 개씩 갈 수 있는 통로 vs 조금 딜레이가 있지만 용량이 아무리 커도 나누어서 무조건 갈 수 있는 통로</p>\n<br />\n<p>또한 원래 스토리지가 열지향 구조로 되어 있다면 최대의 성능을 냅니다.</p>\n<br />\n<ul>\n<li><strong>CPU 처리의 최적화</strong></li>\n</ul>\n<p>Presto는 SQL 실행에 특화된 시스템입니다.(그러니 집계에도 최적화)</p>\n<br />\n<p>SQL 실행 계획을 자바의 바이트 코드로 변환한 후, 여러 개의 Presto 워커 노드에 이를 배포합니다. 그런후, 그것은 런타임 시스템에 의해 기계코드로 변경되죠.</p>\n<br />\n<p>각 머신(워커 노드)내에서는 코드가 멀티 스레드화(리소스 공유)되어 수백 태스크나 병렬 실행됩니다.</p>\n<br />\n<p>이말인 즉슨, CPU 이용 효율이 높다는 것이고 CPU 리소스만 충분하다면 쿼리 실행 속도를 크게 단축시킬 수 있다는 것입니다.</p>\n<br />\n<ul>\n<li><strong>인 메모리 처리에 의한 고속화</strong></li>\n</ul>\n<br />\n<p>인 메모리 처리, 즉 쿼리에 있어서 중간 데이터를 디스크에 쓰는 것이 아닌 메모리 상에서 모두 처리하는 겁니다.</p>\n<br />\n<p>이는 쓸때없는 오버헤드를 줄이고 시간을 단축해줍니다.</p>\n<br />\n<p>즉, 디스크가 있어야 하는 대규모 배치 처리 혹은 거대한 테이블의 결합을 제외한 쿼리에 있어서는 이러한 대화형 쿼리 엔진을 사용하는 것이 효율적입니다.</p>\n<br />  \n<ul>\n<li><strong>분산 결합과 브로드캐스트 결합</strong></li>\n</ul>\n<br />\n<p>분산 결합 : Presto는 기본적으로 분산 결합을 실시하며, 같은 키를 같는 데이터는 동일한 노드에 모입니다.\r\n(기본적으로 팩트 테이블 끼리 집약하는 경우)</p>\n<br />\n<p>브로드캐스트 결합 : 스타스키마와 같이 하나의 팩트 테이블에 여러 디멘전 테이블이 결합하는 경우, 대부분의 디멘전 테이블은 메모리에 들어갈 정도로 충분히 작습니다.</p>\n<br />\n<p>즉 작은 디멘전 테이블을 복사하여 팩트 테이블과 분할 조인을 하게 된다면 굳이 팩트 테이블을 집약했을 때, 재배치 할 필요가 없어 테이블 결합 속도는 더욱 빨라진다는 겁니다.</p>\n<br />\n<p>간단하게 말하자면 분산 결합 시에는 키 별로 노드가 따로 집계하고 나중에 집약 될때, 팩트 테이블을 재 배치해야하지만, 브로드캐스트 결합의 경우 디멘전 테이블 자체와 애초에 조인을 했기에 그대로 재배치 필요없이 테이블이 만들어집니다.</p>\n<br />\n<hr>\n<h3 id=\"데이터-분석-프레임워크-선택하기\" style=\"position:relative;\"><a href=\"#%EB%8D%B0%EC%9D%B4%ED%84%B0-%EB%B6%84%EC%84%9D-%ED%94%84%EB%A0%88%EC%9E%84%EC%9B%8C%ED%81%AC-%EC%84%A0%ED%83%9D%ED%95%98%EA%B8%B0\" aria-label=\"데이터 분석 프레임워크 선택하기 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>데이터 분석 프레임워크 선택하기</h3>\n<br />\n<ul>\n<li><strong>MPP 데이터베이스</strong></li>\n</ul>\n<p>📂 <strong>완성한 비정규화 테이블의 고속 집계에 적합</strong></p>\n<p>기존에 배운 바와 같이 분산과 압축의 기능을 갖춘 MPP 데이터베이스는 집계에 최적화된 열지향 데이터베이스이기에 완성한 비정규화 테이블을 고속으로 집계하는데 뛰어납니다!</p>\n<p>스토리지 및 계산노드가 일체화 되어있기에 ETL 프로세스로 데이터를 가져오는 절차가 필요하죠.</p>\n<br />\n<br />\n<ul>\n<li><strong>Hive</strong></li>\n</ul>\n<p>📂 <strong>데이터양에 좌우되지 않는 쿼리 엔진</strong></p>\n<p>분산 시스템의 동향은 인 메모리의 데이터 처리로 옮겨가고 있습니다.</p>\n<p>하지만 대규모 배치 처리와 같이 무거운 처리는 Hive가 안정성이 높으며, Tez의 등장으로 대화형 쿼리로도 사용됩니다.(물론 둘 다 중간 디스크를 사용)</p>\n<p>중요한 것은 안정성입니다!</p>\n<br />\n<br />\n<ul>\n<li><strong>Presto</strong></li>\n</ul>\n<p>📂 <strong>속도 중시 &#x26; 대화식으로 특화된 쿼리 엔진</strong></p>\n<p>메모리가 부족하면 쿼리를 실행하지 못할 수 있으나, 빠른 속도를 보장합니다.</p>\n<p>Presto는 대화식 쿼리 실행에 특화되어 있어 텍스트 처리가 중심이 되는 ETL 프로세스 및 데이터 구조화에는 적합하지 않습니다.</p>\n<p>데이터 구조화(열 지향 포함)에 있어서는 Hive나 Spark를 사용하는 것이 좋습니다.</p>\n<br />\n<br />\n<ul>\n<li><strong>Spark</strong></li>\n</ul>\n<p>📂 <strong>분산 시스템을 사용한 프로그래밍 환경</strong></p>\n<p>인 메모리의 데이터 처리가 중심이며, Presto와 함께 대화형 쿼리 실행에 적합합니다.</p>\n<p>하지만 Spark의 장점은 SQL이라기 보다는 ETL 프로세스에서 SQL에 이르기까지의 흐름을 하나의 데이터 파이프라인으로 기술할 수 있다는 겁니다.</p>\n<p>이말인 즉, Hive에 의한 데이터 구조화와 Presto에 의한 SQL의 실행에 관해 Spark에서는 하나의 스크립트 안에서 실행 가능할 수 있습니다!</p>\n<p>Spark에서는 메모리 관리가 중요합니다. 여러 번 이용하는 데이터를 캐시에 올려놓거나 디스크에 스왑시켜 메모리를 해제하는 등 프로그래머가 어느정도 제어가 가능합니다.</p>\n<br />\n<hr>\n<h3 id=\"데이터-마트의-구축\" style=\"position:relative;\"><a href=\"#%EB%8D%B0%EC%9D%B4%ED%84%B0-%EB%A7%88%ED%8A%B8%EC%9D%98-%EA%B5%AC%EC%B6%95\" aria-label=\"데이터 마트의 구축 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>데이터 마트의 구축</h3>\n<br />\n<ul>\n<li><strong>팩트 테이블</strong></li>\n</ul>\n<p>이전에 팩트 테이블은 시간에 따라 증가하는 데이터 즉, 시계열 데이터라고 했습니다. 이러한 팩트 테이블은 작으면 메모리 상에 올리는 것이 가능하나, 그렇지 않다면 열 지향 스토리지에 압축의 과정을 거쳐야 빠른 집계가 가능합니다.</p>\n<br />\n<p>팩트 테이블의 작성에는 <strong>추가</strong>와 <strong>치환</strong>의 방법이 존재합니다.</p>\n<br />\n<p>📗 <strong>추가</strong>\r\n새로 도착한 데이터만을 증분</p>\n<br />\n<p>📘 <strong>치환</strong>\r\n과거의 데이터를 포함해 테이블 전체를 치환한다.</p>\n<br />\n<ul>\n<li><strong>테이블 파티셔닝</strong></li>\n</ul>\n<p>효율적인 면에서는 추가가 훨씬 유리합니다. 그러나 추가의 경우 <strong>결손</strong>, <strong>중복</strong>, <strong>관리 복잡</strong>의 문제가 있습니다.</p>\n<br />\n<p>즉, 이러한 문제가 일어날 가능성을 줄이기 위해 물리적으로 파티션을 나누어 파티션 단위로 데이터를 쓰거나 삭제할 수 있도록 <strong>테이블 파티셔닝</strong>을 합니다.</p>\n<br />\n<p>예를 들어 <strong>1일 1회</strong>, 또는 <strong>1시간 1회</strong>라는 형식으로 파티션을 만들고, 각 파티션은 매번 교체하는 형식으로 둡니다. 그리고 이 파티션들을 팩트 테이블에 붙여놓는 겁니다.(즉 추가하는 것)</p>\n<br />\n<p>이렇게 한다면 파티션끼리 서로 비교가 가능하고, 중복 및 결손의 가능성을 줄일 수 있습니다.</p>\n<br />\n<ul>\n<li><strong>데이터 마트의 치환</strong></li>\n</ul>\n<br />\n<p>사실 테이블 파티셔닝은 데이터 웨어하우스를 만드는데 유용합니다. 오히려 데이터 마트를 구축하는데 있어서는 팩트 테이블을 치환하는 것이 중복과 결손을 줄일 수 있는 좋은 방법입니다.</p>\n<br />\n<p>단, <strong>처리시간</strong>이 문제입니다. MPP데이터 베이스라면 쓰기를 병렬화 해서 어느정도 속도를 높일 수 있으나, 그래도 시간이 너무 소요되는 경우에는 테이블 파티셔닝을 실시합니다.</p>\n<br />\n<hr>\n<ul>\n<li><strong>집계 테이블</strong></li>\n</ul>\n<p><code class=\"language-text\">집계 테이블 : 팩트 테이블을 어느정도 모아 집계를 한 것</code></p>\n<br />\n<p>이러한 집계 테이블 만든다면 데이터 마트의 크기는 그다지 커지지 않습니다.</p>\n<p>예시로 데이터를 1일 단위로 집계한 ‘일일 집계’가 있습니다.</p>\n<br />\n<div class=\"gatsby-highlight\" data-language=\"sql\"><pre class=\"language-sql\"><code class=\"language-sql\"><span class=\"token keyword\">CREATE</span> <span class=\"token keyword\">TABLE</span> access_summary STORED <span class=\"token keyword\">AS</span> ORC <span class=\"token keyword\">AS</span>\r\n\r\n<span class=\"token keyword\">SELECT</span> <span class=\"token keyword\">time</span><span class=\"token punctuation\">,</span> <span class=\"token keyword\">status</span>\r\n    <span class=\"token function\">count</span><span class=\"token punctuation\">(</span><span class=\"token operator\">*</span><span class=\"token punctuation\">)</span> count<span class=\"token punctuation\">,</span> <span class=\"token function\">sum</span><span class=\"token punctuation\">(</span>bytes<span class=\"token punctuation\">)</span> bytes\r\n<span class=\"token keyword\">FROM</span> <span class=\"token punctuation\">(</span>\r\n<span class=\"token keyword\">SELECT</span> cast<span class=\"token punctuation\">(</span>substr<span class=\"token punctuation\">(</span><span class=\"token keyword\">time</span><span class=\"token punctuation\">,</span> <span class=\"token number\">1</span><span class=\"token punctuation\">,</span> <span class=\"token number\">10</span><span class=\"token punctuation\">)</span> <span class=\"token keyword\">AS</span> <span class=\"token keyword\">date</span><span class=\"token punctuation\">)</span> <span class=\"token keyword\">time</span><span class=\"token punctuation\">,</span> <span class=\"token keyword\">status</span><span class=\"token punctuation\">,</span> bytes\r\n<span class=\"token keyword\">FROM</span> access_log_orc\r\n<span class=\"token keyword\">WHERE</span> <span class=\"token keyword\">time</span> <span class=\"token operator\">BETWEEN</span> <span class=\"token string\">'1995-07-10'</span> <span class=\"token operator\">AND</span> <span class=\"token string\">'1995-07-20'</span>\r\n<span class=\"token punctuation\">)</span> t\r\n<span class=\"token keyword\">GROUP</span> <span class=\"token keyword\">BY</span> <span class=\"token keyword\">time</span><span class=\"token punctuation\">,</span> <span class=\"token keyword\">status</span></code></pre></div>\n<br />\n<p>해당 구문은 팩트 테이블로 부터 집계를 위해 열 지향으로 팩트 테이블을 집계하는 과정을 나타냅니다.</p>\n<br />\n<p>시간과 상태를 그룹핑하여 총 개수와 바이트 수를 집계합니다.</p>\n<br />\n<p>즉, 열 지향으로 압축 및 서브쿼리화된 팩트 테이블로 부터 일일 집계를 만드는 과정이라 보아도 좋습니다.</p>\n<br />\n<p><strong>카디널리티</strong>, DB를 공부하는 사람이라면 조금은 들어보았을 겁니다.</p>\n<br />\n<p>한마디로 상대적으로 중복이 많냐 적냐의 차이라고 보며 됩니다.</p>\n<br />\n<p>가령 중복되는 요소가 많다면 카디널리티는 적다고 하고, 중복되는 요소가 적다면 카디널리티가 많다고 합니다.</p>\n<br />\n<p>집계 테이블을 작게 하기 위해서는 카디널리티를 적게 만들어야 합니다. 왜냐하면, 중복 요소를 많이 만들어야 총 레코드 수가 줄어들기 때문이죠.</p>\n<br />\n<p>단, 시각화 효율 또한 생각해야기에 균형을 잘 맞추어야 합니다.</p>\n<br />\n<hr>\n<h3 id=\"스냅샷-테이블\" style=\"position:relative;\"><a href=\"#%EC%8A%A4%EB%83%85%EC%83%B7-%ED%85%8C%EC%9D%B4%EB%B8%94\" aria-label=\"스냅샷 테이블 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a><strong>스냅샷 테이블</strong></h3>\n<br />\n<p>이전까지 팩트 테이블의 집계 방법에 대해 알아보았습니다.</p>\n<p>그렇다면 업데이트 될 가능성이 있는 <strong>마스터 데이터</strong>같은 경우에는 두 가지 방안이 존재합니다.</p>\n<br />\n<ol>\n<li>정기적으로 테이블을 통째로 저장 : <strong>스냅샷 테이블</strong></li>\n</ol>\n<br />\n<ol start=\"2\">\n<li>변경 내용만을 저장 : <strong>이력 테이블</strong></li>\n</ol>\n<br />\n<p>스냅샷 테이블이 차후의 데이터 분석에 있어서는 훨씬 취급이 쉽습니다.</p>\n<br />\n<p>스냅샷 테이블은 말그대로 스냅샷 날짜가 저장되어 있습니다.</p>\n<br />\n<p>이 말은 스냅샷을 찍은 날짜에서의 상태값을 가지고 있다는 말이 되고, 팩트 테이블과 결합해 사용할 수 있습니다.</p>\n<br />\n<p>즉, 디멘전 테이블로 사용될 수 있다는 말이죠.</p>\n<br />\n<p>이러한 스냅샷은 특정 시점의 테이블의 상태를 기록한 것이므로 나중에 다시 만들 수 없어 데이터 레이크 혹은 데이터 웨어하우스에 보관해야합니다.</p>\n<br />\n<h3 id=\"이력-테이블\" style=\"position:relative;\"><a href=\"#%EC%9D%B4%EB%A0%A5-%ED%85%8C%EC%9D%B4%EB%B8%94\" aria-label=\"이력 테이블 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a><strong>이력 테이블</strong></h3>\n<br />\n<p>이력 테이블은 변경된 데이터만을 증분으로 스냅샷하거나, 변경이 있을 시 기록하는 형태입니다.</p>\n<br />\n<p>예를 들어 상품 마스터에 대해 상품 가격을 고친다고 해봅시다. 만약 스냅샷 테이블이라면 상품 가격을 고치기 전과 고친 후의 데이터가 모두 시간에 따라 기록이 될 겁니다. 하지만 이력 테이블의 경우에는 고치기 전의 가격 데이터는 가지지 못합니다.</p>\n<br />\n<p>이러한 이유로 디멘전 테이블로는 사용하기 어렵습니다.</p>\n<br />\n<hr>\n<h3 id=\"디멘전을-추가하여-비정규화-테이블-완성하기\" style=\"position:relative;\"><a href=\"#%EB%94%94%EB%A9%98%EC%A0%84%EC%9D%84-%EC%B6%94%EA%B0%80%ED%95%98%EC%97%AC-%EB%B9%84%EC%A0%95%EA%B7%9C%ED%99%94-%ED%85%8C%EC%9D%B4%EB%B8%94-%EC%99%84%EC%84%B1%ED%95%98%EA%B8%B0\" aria-label=\"디멘전을 추가하여 비정규화 테이블 완성하기 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a><strong>디멘전을 추가하여 비정규화 테이블 완성하기</strong></h3>\n<br />\n<p>디멘전 테이블은 마스터 데이터 등으로 이루어진 테이블입니다. 그리고 스냅샷 테이블이 이러한 마스터 데이터의 상태를 모두 기록했으므로 디멘전 테이블로써 적합했습니다.</p>\n<br />\n<p>하지만 목적에 따라 스냅샷 데이터에서 데이터를 추출하여 만든 중간 데이터 또한 디멘전 테이블이라고 불립니다.</p>\n<br />\n<p>중요한 것은 목적입니다! <strong>스냅샷 테이블은 무조건 디멘전 테이블이고, 목적에 따라 디멘전 테이블로써 충분한 역할을 한다면 그 테이블은 디멘전 테이블이다</strong> 라고 저는 생각합니다.</p>\n<br />\n<p>이때 결합하는 디멘전의 <strong>카디널리티가 작아야</strong> 시각화와 활용성에 있어 유용한 비정규화 테이블이 만들어집니다!</p>\n<br />","frontmatter":{"date":"February 13, 2023","title":"빅 데이터를 지탱하는 기술 책 리뷰 - (2)","categories":"Engineer","author":"DEVEL","emoji":"😸"},"fields":{"slug":"/data-engineer-3/"}},"prev":null,"site":{"siteMetadata":{"siteUrl":"https://hsjni0110.github.io/devel-repo","comments":{"utterances":{"repo":"hsjni0110/hsjni0110.github.io"}}}}},"pageContext":{"slug":"/data-engineer-4/","nextSlug":"/data-engineer-3/","prevSlug":""}},"staticQueryHashes":["1073350324","1956554647","2938748437"]}