{"componentChunkName":"component---src-templates-blog-template-js","path":"/data-engineer-3/","result":{"data":{"cur":{"id":"8946dc13-6971-5972-8900-d850c5b3b049","html":"<h2 id=\"제-3장-빅데이터의-분산처리\" style=\"position:relative;\"><a href=\"#%EC%A0%9C-3%EC%9E%A5-%EB%B9%85%EB%8D%B0%EC%9D%B4%ED%84%B0%EC%9D%98-%EB%B6%84%EC%82%B0%EC%B2%98%EB%A6%AC\" aria-label=\"제 3장 빅데이터의 분산처리 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>제 3장. 빅데이터의 분산처리</h2>\n<br />\n<ul>\n<li><strong>스키마</strong></li>\n</ul>\n<p>테이블의 칼럼 명과 데이터형, 테이블 간의 관계 등</p>\n<ul>\n<li><strong>구조화된 데이터</strong></li>\n</ul>\n<p>스키마가 명확하게 정의된 데이터</p>\n<ul>\n<li><strong>비구조화 데이터</strong></li>\n</ul>\n<p>스키마가 없는 데이터</p>\n<ul>\n<li><strong>데이터 레이크</strong></li>\n</ul>\n<p>비구조화 데이터를 분산 스토리지에 저장하고 그것을 분산 시스템에서 처리하는 것</p>\n<ul>\n<li><strong>스키마리스 데이터</strong></li>\n</ul>\n<p>CSV, JSON, XML 등의 데이터와 같이 서식은 정해져 있지만, 칼럼 수나 데이터 형은 명확하지 않은 데이터</p>\n<br />\n<p>비구조화 데이터에서 구조화 데이터로 변환하고 일반적으로 구조화 데이터를 열 지향 스토리지로 저장합니다.</p>\n<br />\n<p>이를 위해 MPP 데이터베이스로 전송하거나 Hadoop 상에서 열 지향 스토리지 형식으로 변환합니다.</p>\n<br />\n<hr>\n<br />\n<p>Hadoop에서는 사용자가 직접 열 지향 스토리지 형식을 지정할 수 있고 그 특징이 다릅니다.</p>\n<br />\n<p>Apache ORC : 구조화 데이터를 위한 열 지향 스토리지</p>\n<p>Apache Parquet : 스키마리스 데이터 구조 처리 가능</p>\n<p>Hadoop : 단일 소프트웨어가 아닌 분산 시스템을 구성하는 다수의 소프트웨어로 이루어진 집합체</p>\n<br />\n<h3 id=\"hadoop의-구성요소\" style=\"position:relative;\"><a href=\"#hadoop%EC%9D%98-%EA%B5%AC%EC%84%B1%EC%9A%94%EC%86%8C\" aria-label=\"hadoop의 구성요소 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a><strong>Hadoop의 구성요소</strong></h3>\n<br />\n<p>분산 파일 시스템 : HDFS(Hadoop Distributed File System)</p>\n<p>리소스 관리자 : YARN(Yet Another Resource Negotiator)</p>\n<p>분산 데이터 처리의 기반 : MapReduce</p>\n<br />\n<ul>\n<li>HDFS, YARN의 역할</li>\n</ul>\n<p>데이터의 대부분은 분산 파일 시스템인 HDFS에 저장됩니다. CPU나 메모리 등의 계산 리소스는 리소스 매니저인 YARN에의해 관리되고 컨테이너라는 단위로 관리되죠.</p>\n<br />\n<h3 id=\"mapreduce\" style=\"position:relative;\"><a href=\"#mapreduce\" aria-label=\"mapreduce permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a><strong>MapReduce</strong></h3>\n<p>MapReduce도 YARN 상에서 동작하는 분산 애플리케이션 중 하나입니다.</p>\n<br />\n<p>데이터 처리를 담당하며 임의의 자바 프로그램을 실행하여 비구조화 데이터 처리에 뛰어납니다.</p>\n<br />\n<p>Apache Hive의 경우에는 MapReduce에 의존하는 쿼리 엔진입니다.(정확히는 쿼리를 쿼리를 MapReduce 프로그램으로 변환)</p>\n<br />\n<p>MapReduce는 대용량 데이터 배치처리에 적합합니다. 따라서 Hive도 배치 처리에 적합합니다.</p>\n<h3 id=\"hive-on-tez\" style=\"position:relative;\"><a href=\"#hive-on-tez\" aria-label=\"hive on tez permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Hive on Tez</h3>\n<p>Hive를 가속화하기 위한 노력으로 Apache Tez가 등장했습니다. 기존의 Hive의 경우 하나의 쿼리를 처리하는데 여러 스테이지를 나누어 처리했습니다.</p>\n<p>이는 가속화에 있어 어느정도 걸림돌이 되었고, Tez가 스테이지의 종료를 기다리지 않고 다음 스테이지로 먼저 처리된 데이터를 보낼 수 있게 됨으로써 이를 보완합니다.</p>\n<br />\n<ul>\n<li>Hive on Tez</li>\n<li>Hive on MR</li>\n</ul>\n<br />\n<h3 id=\"대화형-쿼리-엔진\" style=\"position:relative;\"><a href=\"#%EB%8C%80%ED%99%94%ED%98%95-%EC%BF%BC%EB%A6%AC-%EC%97%94%EC%A7%84\" aria-label=\"대화형 쿼리 엔진 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a><strong>대화형 쿼리 엔진</strong></h3>\n<p>앞서 말했듯이 대화형 쿼리 엔진에는 MPP 데이터베이스 아키텍처 기반이 있다고 했습니다. 물론 완벽한 압축의 역할은 못한다고 했지만요.</p>\n<p>하지만 여러 CPU를 사용하는 멀티스레드를 사용하여 오버헤드를 최대한 줄인다는 점에서 ‘분산’의 역할은 충실히 하고 있는 것이지요.</p>\n<p>대표적으로 Apache Implala(아파치 임팔라)와 Presto가 대표적입니다.</p>\n<p>즉, 이 과정에서 데이터 마트로 만드는데 MPP 데이터베이스보단 못하지만, Hadoop 환경에서 호환되어 사용되는 겁니다.</p>\n<br />\r\n<br />\n<h3 id=\"정리\" style=\"position:relative;\"><a href=\"#%EC%A0%95%EB%A6%AC\" aria-label=\"정리 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>정리</h3>\n<p>무거운 배치 처리에 있어서는 Hive 이용, 주로 비구조화 데이터를 구조화로 처리(데이터레이크와 데이터 마트 사이에서 비 구조화 데이터를 구조화 데이터로)</p>\n<br />\r\n구조화 데이터를 대화식 집계하기 위해 주로 Impala, Presto를 통해 지연을 줄임\r\n(데이터 마트로 만듬)\n<hr>\n<br />\n<h3 id=\"spark\" style=\"position:relative;\"><a href=\"#spark\" aria-label=\"spark permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a><strong>Spark</strong></h3>\n<p>Spark는 MapReduce를 대체하는 존재입니다. 즉, 분산 파일 시스템은 HDFS, 리소스 관리자는 YARN으로 사용할 수 있다는 것이죠.</p>\n<br />\n<p>Spark의 특징은 중간 데이터를 디스크에 쓰지 않고, 메모리에 보존합니다. 따라서 중간 데이터를 읽어버려도 입력 데이터로 다시 실행합니다.</p>\n<br />\n<hr>\n<br />\n<p>Hive에서 만든 각 테이블의 정보는 ‘Hive 메타 스토어’라는 특별한 데이터베이스에 저장됩니다. 즉, 여기에 비정규화 테이블 직전의 테이블인 디멘전 테이블과 팩트 테이블이 존재하는 것이지요.</p>\n<br />\n<p>펙트 테이블은 트랜잭션과 같이 시간과 같이 생성되는 데이터로 이루어진 테이블, 디멘전 테이블은 재 사용 가능한 데이터인 마스터 테이블로 이루어진 테이블이었습니다.(열 지향 or 행 지향)</p>\n<br />\n<p>이 두 테이블을 이용하여 우리는 비정규화 테이블을 작성해야 합니다.\r\n이때, Presto와 같은 대화형 쿼리 엔진을 이용할지, Hive 같은 배치형 쿼리 엔진을 사용해야 할 지는 생각에 따라 달라집니다.</p>\n<br />\n<p>우리는 시간이 걸리는 배치 처리의 경우이므로 Hive를 사용할 것입니다.\r\n하지만, 비정규화 테이블은 만드는 것은 오랜 시간이 걸리는 일이므로 쿼리를 개선하는 방법을 알아야합니다. 방법은 다음과 같습니다.</p>\n<br />\n<ol>\n<li>\n<p><strong>서브 쿼리 안에서 레코드 수 줄이기</strong></p>\n<p>기존의 팩트 테이블(“access_log”)과 디멘전 테이블(“user”)을 결합하고 WHERE로 조건을 부여하는 쿼리는 간단하지만 비효율적입니다.</p>\n<p>따라서 팩트 테이블을 작게 만들고 데이터를 집계하는 것이 시간 단축에 효율적입니다.</p>\n<div class=\"gatsby-highlight\" data-language=\"sql\"><pre class=\"language-sql\"><code class=\"language-sql\"><span class=\"token keyword\">SELECT</span> <span class=\"token punctuation\">.</span><span class=\"token punctuation\">.</span><span class=\"token punctuation\">.</span>\r\n<span class=\"token keyword\">FROM</span> <span class=\"token punctuation\">(</span>\r\n    <span class=\"token keyword\">SELECT</span> <span class=\"token operator\">*</span> access_log\r\n    <span class=\"token keyword\">WHERE</span> <span class=\"token keyword\">time</span> <span class=\"token operator\">>=</span> <span class=\"token keyword\">TIMESTAMP</span> <span class=\"token string\">'2017-01-01 00:00:00'</span>\r\n<span class=\"token punctuation\">)</span> a\r\n<span class=\"token keyword\">JOIN</span> users b <span class=\"token keyword\">ON</span> b<span class=\"token punctuation\">.</span>id <span class=\"token operator\">=</span> a<span class=\"token punctuation\">.</span>user_id\r\n<span class=\"token keyword\">WHERE</span> b<span class=\"token punctuation\">.</span>created_at <span class=\"token operator\">=</span> <span class=\"token string\">'2017-01-01'</span></code></pre></div>\n</li>\n</ol>\n<br />\n<br />\n<ol start=\"2\">\n<li><strong>데이터 편향 피하기</strong></li>\n</ol>\n<p>만약 분산 시스템에서 고유한 어떤 종류를 카운트한다고 하자. 그렇다면 중복이 없는 값을 세기 위해 데이터를 한 곳에 모아야 하기에 분산 처리가 어려울 것입니다.(select distinct…)</p>\n<br />\n<p>이 문제를 해결하기 위해 GROUP BY를 통해 분산처리를 실행해 줍니다. 하지만 이 또한 GROUP BY를 각각 한 단위 안에서(즉 한 CPU 안에서) 많은 중복값이 존재한다면 다른 처리 시간 보다 많은 시간이 걸릴 것입니다.</p>\n<br />\n<p>이를 예방하기 위해, 즉 데이터의 편향 문제를 해결하기 위해 모든 노드에 데이터가 균등하게 분산되도록 해야 합니다. 즉, 중복을 <strong>최초에 줄인</strong> 테이블에서 선택하는 것입니다!</p>\n<br />\n<div class=\"gatsby-highlight\" data-language=\"sql\"><pre class=\"language-sql\"><code class=\"language-sql\"><span class=\"token keyword\">SELECT</span> <span class=\"token keyword\">date</span><span class=\"token punctuation\">,</span> <span class=\"token function\">count</span><span class=\"token punctuation\">(</span><span class=\"token operator\">*</span><span class=\"token punctuation\">)</span> users\r\n<span class=\"token keyword\">FROM</span> <span class=\"token punctuation\">(</span>\r\n    <span class=\"token keyword\">SELECT</span> <span class=\"token keyword\">DISTINCT</span> <span class=\"token keyword\">date</span><span class=\"token punctuation\">,</span> user_id <span class=\"token keyword\">FROM</span> access_log\r\n<span class=\"token punctuation\">)</span> t\r\n<span class=\"token keyword\">GROUP</span> <span class=\"token keyword\">BY</span> <span class=\"token keyword\">date</span></code></pre></div>\n<br />\n<hr>\n<h3 id=\"대화형-쿼리-엔진-presto의-구조와-특징\" style=\"position:relative;\"><a href=\"#%EB%8C%80%ED%99%94%ED%98%95-%EC%BF%BC%EB%A6%AC-%EC%97%94%EC%A7%84-presto%EC%9D%98-%EA%B5%AC%EC%A1%B0%EC%99%80-%ED%8A%B9%EC%A7%95\" aria-label=\"대화형 쿼리 엔진 presto의 구조와 특징 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a><strong>대화형 쿼리 엔진 Presto의 구조와 특징</strong></h3>\n<br />\n<p>대화형 쿼리엔진  : 쿼리 실행의 지연을 감소시키는 것이 목적</p>\n<br />\n<ul>\n<li><strong>플러그인 가능한 스토리지</strong></li>\n</ul>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 720px; \"\n    >\n      <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 54.44444444444444%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAALCAYAAAB/Ca1DAAAACXBIWXMAAB2HAAAdhwGP5fFlAAABAUlEQVQoz42T2Y6DMAxF8/9f2tIBJglLWF0djy5CCHX6cJXE2MdLQljX1a6apslVSrFlWdy2bZvd+V4VzgeCAKWUrGkaF2fsgAX/Gojmeba+7+3n9XIwwGEYrOs6F3vB8b0mCXet7Ptu4zi6M3AqBf4bo+WUHYrw4TtgcYIyKKvaY34EaY4EF1SKJ0TYSYTfASRDXdcWY/SWWFFVVb5OpfxVWdful2JyeNu21vWdA4nTrIPmozaoIOdsz8fzuBQA2BC+VIIviTRj4hx4HbBa1hwVCCyl7Hv5IyrFdrTMRjo/H+3VHq0xAsDYJCo7x4X/3tX5kpBu9K6Q23f4CfzNn/IGO8lcuyK1wWYAAAAASUVORK5CYII='); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"Presto구조\"\n        title=\"Presto구조\"\n        src=\"/static/3802db66de6514ddeaef301b1c5ffcc5/37523/Presto%EA%B5%AC%EC%A1%B0.png\"\n        srcset=\"/static/3802db66de6514ddeaef301b1c5ffcc5/e9ff0/Presto%EA%B5%AC%EC%A1%B0.png 180w,\n/static/3802db66de6514ddeaef301b1c5ffcc5/f21e7/Presto%EA%B5%AC%EC%A1%B0.png 360w,\n/static/3802db66de6514ddeaef301b1c5ffcc5/37523/Presto%EA%B5%AC%EC%A1%B0.png 720w,\n/static/3802db66de6514ddeaef301b1c5ffcc5/302a4/Presto%EA%B5%AC%EC%A1%B0.png 1080w,\n/static/3802db66de6514ddeaef301b1c5ffcc5/07a9c/Presto%EA%B5%AC%EC%A1%B0.png 1440w,\n/static/3802db66de6514ddeaef301b1c5ffcc5/df438/Presto%EA%B5%AC%EC%A1%B0.png 1556w\"\n        sizes=\"(max-width: 720px) 100vw, 720px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n        decoding=\"async\"\n      />\n    </span></p>\n<p>Presto는 Hive와 마찬가지로 데이터 소스에서 직접 데이터를 읽어들입니다.(처음에 데이터를 가지고 있어야 하는 MPP 데이터베이스와는 상반)</p>\n<p>비구조화 데이터를 구조화 데이터로 만드는데 쓰일 수도 있으나 Hive보다 크게 뛰어나지 않습니다. 즉 구조화 데이터를 집계하는데 주 목적을 둡니다.</p>\n<br />\n<p>🔥 <strong>왜 안되는데?</strong></p>\n<br />\n<p>가령 텍스트 처리가 중심인 ETL프로세스 및 데이터 구조화는 대화형 쿼리엔진이 적합하지 않습니다.</p>\n<br />\n<p>빠르지만 적절한 용량으로 한 개씩 갈 수 있는 통로 vs 조금 딜레이가 있지만 용량이 아무리 커도 나누어서 무조건 갈 수 있는 통로</p>\n<br />\n<p>또한 원래 스토리지가 열지향 구조로 되어 있다면 최대의 성능을 냅니다.</p>\n<br />\n<ul>\n<li><strong>CPU 처리의 최적화</strong></li>\n</ul>\n<p>Presto는 SQL 실행에 특화된 시스템입니다.(그러니 집계에도 최적화)</p>\n<br />\n<p>SQL 실행 계획을 자바의 바이트 코드로 변환한 후, 여러 개의 Presto 워커 노드에 이를 배포합니다. 그런후, 그것은 런타임 시스템에 의해 기계코드로 변경되죠.</p>\n<br />\n<p>각 머신(워커 노드)내에서는 코드가 멀티 스레드화(리소스 공유)되어 수백 태스크나 병렬 실행됩니다.</p>\n<br />\n<p>이말인 즉슨, CPU 이용 효율이 높다는 것이고 CPU 리소스만 충분하다면 쿼리 실행 속도를 크게 단축시킬 수 있다는 것입니다.</p>\n<br />\n<ul>\n<li><strong>인 메모리 처리에 의한 고속화</strong></li>\n</ul>\n<br />\n<p>인 메모리 처리, 즉 쿼리에 있어서 중간 데이터를 디스크에 쓰는 것이 아닌 메모리 상에서 모두 처리하는 겁니다.</p>\n<br />\n<p>이는 쓸때없는 오버헤드를 줄이고 시간을 단축해줍니다.</p>\n<br />\n<p>즉, 디스크가 있어야 하는 대규모 배치 처리 혹은 거대한 테이블의 결합을 제외한 쿼리에 있어서는 이러한 대화형 쿼리 엔진을 사용하는 것이 효율적입니다.</p>\n<br />  \n<ul>\n<li><strong>분산 결합과 브로드캐스트 결합</strong></li>\n</ul>\n<br />\n<p>분산 결합 : Presto는 기본적으로 분산 결합을 실시하며, 같은 키를 같는 데이터는 동일한 노드에 모입니다.\r\n(기본적으로 팩트 테이블 끼리 집약하는 경우)</p>\n<br />\n<p>브로드캐스트 결합 : 스타스키마와 같이 하나의 팩트 테이블에 여러 디멘전 테이블이 결합하는 경우, 대부분의 디멘전 테이블은 메모리에 들어갈 정도로 충분히 작습니다.</p>\n<br />\n<p>즉 작은 디멘전 테이블을 복사하여 팩트 테이블과 분할 조인을 하게 된다면 굳이 팩트 테이블을 집약했을 때, 재배치 할 필요가 없어 테이블 결합 속도는 더욱 빨라진다는 겁니다.</p>\n<br />\n<p>간단하게 말하자면 분산 결합 시에는 키 별로 노드가 따로 집계하고 나중에 집약 될때, 팩트 테이블을 재 배치해야하지만, 브로드캐스트 결합의 경우 디멘전 테이블 자체와 애초에 조인을 했기에 그대로 재배치 필요없이 테이블이 만들어집니다.</p>\n<br />\n<hr>\n<h3 id=\"데이터-분석-프레임워크-선택하기\" style=\"position:relative;\"><a href=\"#%EB%8D%B0%EC%9D%B4%ED%84%B0-%EB%B6%84%EC%84%9D-%ED%94%84%EB%A0%88%EC%9E%84%EC%9B%8C%ED%81%AC-%EC%84%A0%ED%83%9D%ED%95%98%EA%B8%B0\" aria-label=\"데이터 분석 프레임워크 선택하기 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>데이터 분석 프레임워크 선택하기</h3>\n<br />\n<ul>\n<li><strong>MPP 데이터베이스</strong></li>\n</ul>\n<p>📂 <strong>완성한 비정규화 테이블의 고속 집계에 적합</strong></p>\n<p>기존에 배운 바와 같이 분산과 압축의 기능을 갖춘 MPP 데이터베이스는 집계에 최적화된 열지향 데이터베이스이기에 완성한 비정규화 테이블을 고속으로 집계하는데 뛰어납니다!</p>\n<p>스토리지 및 계산노드가 일체화 되어있기에 ETL 프로세스로 데이터를 가져오는 절차가 필요하죠.</p>\n<br />\n<br />\n<ul>\n<li><strong>Hive</strong></li>\n</ul>\n<p>📂 <strong>데이터양에 좌우되지 않는 쿼리 엔진</strong></p>\n<p>분산 시스템의 동향은 인 메모리의 데이터 처리로 옮겨가고 있습니다.</p>\n<p>하지만 대규모 배치 처리와 같이 무거운 처리는 Hive가 안정성이 높으며, Tez의 등장으로 대화형 쿼리로도 사용됩니다.(물론 둘 다 중간 디스크를 사용)</p>\n<p>중요한 것은 안정성입니다!</p>\n<br />\n<br />\n<ul>\n<li><strong>Presto</strong></li>\n</ul>\n<p>📂 <strong>속도 중시 &#x26; 대화식으로 특화된 쿼리 엔진</strong></p>\n<p>메모리가 부족하면 쿼리를 실행하지 못할 수 있으나, 빠른 속도를 보장합니다.</p>\n<p>Presto는 대화식 쿼리 실행에 특화되어 있어 텍스트 처리가 중심이 되는 ETL 프로세스 및 데이터 구조화에는 적합하지 않습니다.</p>\n<p>데이터 구조화(열 지향 포함)에 있어서는 Hive나 Spark를 사용하는 것이 좋습니다.</p>\n<br />\n<br />\n<ul>\n<li><strong>Spark</strong></li>\n</ul>\n<p>📂 <strong>분산 시스템을 사용한 프로그래밍 환경</strong></p>\n<p>인 메모리의 데이터 처리가 중심이며, Presto와 함께 대화형 쿼리 실행에 적합합니다.</p>\n<p>하지만 Spark의 장점은 SQL이라기 보다는 ETL 프로세스에서 SQL에 이르기까지의 흐름을 하나의 데이터 파이프라인으로 기술할 수 있다는 겁니다.</p>\n<p>이말인 즉, Hive에 의한 데이터 구조화와 Presto에 의한 SQL의 실행에 관해 Spark에서는 하나의 스크립트 안에서 실행 가능할 수 있습니다!</p>\n<p>Spark에서는 메모리 관리가 중요합니다. 여러 번 이용하는 데이터를 캐시에 올려놓거나 디스크에 스왑시켜 메모리를 해제하는 등 프로그래머가 어느정도 제어가 가능합니다.</p>\n<br />\n<hr>\n<h3 id=\"데이터-마트의-구축\" style=\"position:relative;\"><a href=\"#%EB%8D%B0%EC%9D%B4%ED%84%B0-%EB%A7%88%ED%8A%B8%EC%9D%98-%EA%B5%AC%EC%B6%95\" aria-label=\"데이터 마트의 구축 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>데이터 마트의 구축</h3>\n<br />\n<ul>\n<li><strong>팩트 테이블</strong></li>\n</ul>\n<p>이전에 팩트 테이블은 시간에 따라 증가하는 데이터 즉, 시계열 데이터라고 했습니다. 이러한 팩트 테이블은 작으면 메모리 상에 올리는 것이 가능하나, 그렇지 않다면 열 지향 스토리지에 압축의 과정을 거쳐야 빠른 집계가 가능합니다.</p>\n<br />\n<p>팩트 테이블의 작성에는 <strong>추가</strong>와 <strong>치환</strong>의 방법이 존재합니다.</p>\n<br />\n<p>📗 <strong>추가</strong>\r\n새로 도착한 데이터만을 증분</p>\n<br />\n<p>📘 <strong>치환</strong>\r\n과거의 데이터를 포함해 테이블 전체를 치환한다.</p>\n<br />\n<ul>\n<li><strong>테이블 파티셔닝</strong></li>\n</ul>\n<p>효율적인 면에서는 추가가 훨씬 유리합니다. 그러나 추가의 경우 <strong>결손</strong>, <strong>중복</strong>, <strong>관리 복잡</strong>의 문제가 있습니다.</p>\n<br />\n<p>즉, 이러한 문제가 일어날 가능성을 줄이기 위해 물리적으로 파티션을 나누어 파티션 단위로 데이터를 쓰거나 삭제할 수 있도록 <strong>테이블 파티셔닝</strong>을 합니다.</p>\n<br />\n<p>예를 들어 <strong>1일 1회</strong>, 또는 <strong>1시간 1회</strong>라는 형식으로 파티션을 만들고, 각 파티션은 매번 교체하는 형식으로 둡니다. 그리고 이 파티션들을 팩트 테이블에 붙여놓는 겁니다.(즉 추가하는 것)</p>\n<br />\n<p>이렇게 한다면 파티션끼리 서로 비교가 가능하고, 중복 및 결손의 가능성을 줄일 수 있습니다.</p>\n<br />\n<ul>\n<li><strong>데이터 마트의 치환</strong></li>\n</ul>\n<br />\n<p>사실 테이블 파티셔닝은 데이터 웨어하우스를 만드는데 유용합니다. 오히려 데이터 마트를 구축하는데 있어서는 팩트 테이블을 치환하는 것이 중복과 결손을 줄일 수 있는 좋은 방법입니다.</p>\n<br />\n<p>단, <strong>처리시간</strong>이 문제입니다. MPP데이터 베이스라면 쓰기를 병렬화 해서 어느정도 속도를 높일 수 있으나, 그래도 시간이 너무 소요되는 경우에는 테이블 파티셔닝을 실시합니다.</p>\n<br />\n<hr>\n<ul>\n<li><strong>집계 테이블</strong></li>\n</ul>\n<p><code class=\"language-text\">집계 테이블 : 팩트 테이블을 어느정도 모아 집계를 한 것</code></p>\n<br />\n<p>이러한 집계 테이블 만든다면 데이터 마트의 크기는 그다지 커지지 않습니다.</p>\n<p>예시로 데이터를 1일 단위로 집계한 ‘일일 집계’가 있습니다.</p>\n<br />\n<div class=\"gatsby-highlight\" data-language=\"sql\"><pre class=\"language-sql\"><code class=\"language-sql\"><span class=\"token keyword\">CREATE</span> <span class=\"token keyword\">TABLE</span> access_summary STORED <span class=\"token keyword\">AS</span> ORC <span class=\"token keyword\">AS</span>\r\n\r\n<span class=\"token keyword\">SELECT</span> <span class=\"token keyword\">time</span><span class=\"token punctuation\">,</span> <span class=\"token keyword\">status</span>\r\n    <span class=\"token function\">count</span><span class=\"token punctuation\">(</span><span class=\"token operator\">*</span><span class=\"token punctuation\">)</span> count<span class=\"token punctuation\">,</span> <span class=\"token function\">sum</span><span class=\"token punctuation\">(</span>bytes<span class=\"token punctuation\">)</span> bytes\r\n<span class=\"token keyword\">FROM</span> <span class=\"token punctuation\">(</span>\r\n<span class=\"token keyword\">SELECT</span> cast<span class=\"token punctuation\">(</span>substr<span class=\"token punctuation\">(</span><span class=\"token keyword\">time</span><span class=\"token punctuation\">,</span> <span class=\"token number\">1</span><span class=\"token punctuation\">,</span> <span class=\"token number\">10</span><span class=\"token punctuation\">)</span> <span class=\"token keyword\">AS</span> <span class=\"token keyword\">date</span><span class=\"token punctuation\">)</span> <span class=\"token keyword\">time</span><span class=\"token punctuation\">,</span> <span class=\"token keyword\">status</span><span class=\"token punctuation\">,</span> bytes\r\n<span class=\"token keyword\">FROM</span> access_log_orc\r\n<span class=\"token keyword\">WHERE</span> <span class=\"token keyword\">time</span> <span class=\"token operator\">BETWEEN</span> <span class=\"token string\">'1995-07-10'</span> <span class=\"token operator\">AND</span> <span class=\"token string\">'1995-07-20'</span>\r\n<span class=\"token punctuation\">)</span> t\r\n<span class=\"token keyword\">GROUP</span> <span class=\"token keyword\">BY</span> <span class=\"token keyword\">time</span><span class=\"token punctuation\">,</span> <span class=\"token keyword\">status</span></code></pre></div>\n<br />\n<p>해당 구문은 팩트 테이블로 부터 집계를 위해 열 지향으로 팩트 테이블을 집계하는 과정을 나타냅니다.</p>\n<br />\n<p>시간과 상태를 그룹핑하여 총 개수와 바이트 수를 집계합니다.</p>\n<br />\n<p>즉, 열 지향으로 압축 및 서브쿼리화된 팩트 테이블로 부터 일일 집계를 만드는 과정이라 보아도 좋습니다.</p>\n<br />\n<p><strong>카디널리티</strong>, DB를 공부하는 사람이라면 조금은 들어보았을 겁니다.</p>\n<br />\n<p>한마디로 상대적으로 중복이 많냐 적냐의 차이라고 보며 됩니다.</p>\n<br />\n<p>가령 중복되는 요소가 많다면 카디널리티는 적다고 하고, 중복되는 요소가 적다면 카디널리티가 많다고 합니다.</p>\n<br />\n<p>집계 테이블을 작게 하기 위해서는 카디널리티를 적게 만들어야 합니다. 왜냐하면, 중복 요소를 많이 만들어야 총 레코드 수가 줄어들기 때문이죠.</p>\n<br />\n<p>단, 시각화 효율 또한 생각해야기에 균형을 잘 맞추어야 합니다.</p>\n<br />\n<hr>\n<h3 id=\"스냅샷-테이블\" style=\"position:relative;\"><a href=\"#%EC%8A%A4%EB%83%85%EC%83%B7-%ED%85%8C%EC%9D%B4%EB%B8%94\" aria-label=\"스냅샷 테이블 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a><strong>스냅샷 테이블</strong></h3>\n<br />\n<p>이전까지 팩트 테이블의 집계 방법에 대해 알아보았습니다.</p>\n<p>그렇다면 업데이트 될 가능성이 있는 <strong>마스터 데이터</strong>같은 경우에는 두 가지 방안이 존재합니다.</p>\n<br />\n<ol>\n<li>정기적으로 테이블을 통째로 저장 : <strong>스냅샷 테이블</strong></li>\n</ol>\n<br />\n<ol start=\"2\">\n<li>변경 내용만을 저장 : <strong>이력 테이블</strong></li>\n</ol>\n<br />\n<p>스냅샷 테이블이 차후의 데이터 분석에 있어서는 훨씬 취급이 쉽습니다.</p>\n<br />\n<p>스냅샷 테이블은 말그대로 스냅샷 날짜가 저장되어 있습니다.</p>\n<br />\n<p>이 말은 스냅샷을 찍은 날짜에서의 상태값을 가지고 있다는 말이 되고, 팩트 테이블과 결합해 사용할 수 있습니다.</p>\n<br />\n<p>즉, 디멘전 테이블로 사용될 수 있다는 말이죠.</p>\n<br />\n<p>이러한 스냅샷은 특정 시점의 테이블의 상태를 기록한 것이므로 나중에 다시 만들 수 없어 데이터 레이크 혹은 데이터 웨어하우스에 보관해야합니다.</p>\n<br />\n<h3 id=\"이력-테이블\" style=\"position:relative;\"><a href=\"#%EC%9D%B4%EB%A0%A5-%ED%85%8C%EC%9D%B4%EB%B8%94\" aria-label=\"이력 테이블 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a><strong>이력 테이블</strong></h3>\n<br />\n<p>이력 테이블은 변경된 데이터만을 증분으로 스냅샷하거나, 변경이 있을 시 기록하는 형태입니다.</p>\n<br />\n<p>예를 들어 상품 마스터에 대해 상품 가격을 고친다고 해봅시다. 만약 스냅샷 테이블이라면 상품 가격을 고치기 전과 고친 후의 데이터가 모두 시간에 따라 기록이 될 겁니다. 하지만 이력 테이블의 경우에는 고치기 전의 가격 데이터는 가지지 못합니다.</p>\n<br />\n<p>이러한 이유로 디멘전 테이블로는 사용하기 어렵습니다.</p>\n<br />\n<hr>\n<h3 id=\"디멘전을-추가하여-비정규화-테이블-완성하기\" style=\"position:relative;\"><a href=\"#%EB%94%94%EB%A9%98%EC%A0%84%EC%9D%84-%EC%B6%94%EA%B0%80%ED%95%98%EC%97%AC-%EB%B9%84%EC%A0%95%EA%B7%9C%ED%99%94-%ED%85%8C%EC%9D%B4%EB%B8%94-%EC%99%84%EC%84%B1%ED%95%98%EA%B8%B0\" aria-label=\"디멘전을 추가하여 비정규화 테이블 완성하기 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a><strong>디멘전을 추가하여 비정규화 테이블 완성하기</strong></h3>\n<br />\n<p>디멘전 테이블은 마스터 데이터 등으로 이루어진 테이블입니다. 그리고 스냅샷 테이블이 이러한 마스터 데이터의 상태를 모두 기록했으므로 디멘전 테이블로써 적합했습니다.</p>\n<br />\n<p>하지만 목적에 따라 스냅샷 데이터에서 데이터를 추출하여 만든 중간 데이터 또한 디멘전 테이블이라고 불립니다.</p>\n<br />\n<p>중요한 것은 목적입니다! <strong>스냅샷 테이블은 무조건 디멘전 테이블이고, 목적에 따라 디멘전 테이블로써 충분한 역할을 한다면 그 테이블은 디멘전 테이블이다</strong> 라고 저는 생각합니다.</p>\n<br />\n<p>이때 결합하는 디멘전의 <strong>카디널리티가 작아야</strong> 시각화와 활용성에 있어 유용한 비정규화 테이블이 만들어집니다!</p>\n<br />","excerpt":"제 3장. 빅데이터의 분산처리 스키마 테이블의 칼럼 명과 데이터형, 테이블 간의 관계 등 구조화된 데이터 스키마가 명확하게 정의된 데이터 비구조화 데이터 스키마가 없는 데이터 데이터 레이크 비구조화 데이터를 분산 스토리지에 저장하고 그것을 분산 시스템에서 처리하는 것 스키마리스 데이터 CSV, JSON, XML 등의 데이터와 같이 서식은 정해져 있지만, 칼럼 수나 데이터 형은 명확하지 않은 데이터 비구조화 데이터에서 구조화 데이터로 변환하고 일반적으로 구조화 데이터를 열 지향 스토리지로 저장합니다. 이를 위해 MPP 데이터베이스로 전송하거나 Hadoop 상에서 열 지향 스토리지 형식으로 변환합니다. Hadoop에서는 사용자가 직접 열 지향 스토리지 형식을 지정할 수 있고 그 특징이 다릅니다. Apache ORC : 구조화 데이터를 위한 열 지향 스토리지 Apache Parquet : 스키마리스 데이터 구조 처리 가능 Hadoop : 단일 소프트웨어가 아닌 분산 시스템을 구성하는 다…","frontmatter":{"date":"February 13, 2023","title":"빅 데이터를 지탱하는 기술 책 리뷰 - (2)","categories":"Engineer","author":"DEVEL","emoji":"😸"},"fields":{"slug":"/data-engineer-3/"}},"next":{"id":"1b215349-3833-5501-8d2a-d9c2fe3aff0f","html":"<p>이 책은 빅데이터를 다루는 엔지니어와 작업을 자동화하고 싶은 데이터 과학자를 주요 대상으로 합니다.</p>\n<br />\n<p>데이터를 수집하고 원하는 형태로 구축하는 것에 있어 초입자인 저에게 있어 많은 깨달음을 준 책이기도 합니다.</p>\n<p>책의 구성은 다음과 같습니다.</p>\n<br />\n<p>제1장은 ‘빅데이터의 기초지식’</p>\n<br />\n<p>제2장 ‘빅데이터의 검색’에서는 데이터의 ‘대화적인 집계와 시각화’ 및 ‘데이터 마트’의 성질</p>\n<br />\n<p>제3장 ‘빅데이터 분산 처리’를 위한 Hadoop(하둡)과 Spark(스파크) 등의 ‘분산 처리 프레임워크’를 통해 데이터 가공 및 집계, 데이터 마트를 만들어내는 프로세스를 설명합니다.</p>\n<br />\n<p>제4장 ‘빅데이터 축적’은 데이터를 수집해서 보존하는 절차를 설명합니다. 여기서는 몇몇 분산 스토리지의 특징을 다루고 분산 스토리지에 데이터를 넣는 ‘데이터 수집’에 관해 설명합니다.</p>\n<br />\n<p>제5장 ‘빅데이터 파이프라인’은 데이터 처리를 자동화하는 절차를 설명합니다. 정기적으로 스케쥴이 실행되는 ‘배치 처리’와 끊임없이 실행되는 ‘스트림 처리’에 관해 배웁니다.</p>\n<br />\n<p>제6장 ‘빅데이터 분석 기반의 구축’은 응용 편으로 데이터 분석, 이해, 데이터 처리 및 데이터 마트 업데이트 자동화에 관해 실습하고 각종 기술이 실제 클라우드 서비스에서 어떤 형태로 제공되는지 배우게 됩니다.</p>\n<br />\n<h2 id=\"제-1장-빅데이터-기초-지식\" style=\"position:relative;\"><a href=\"#%EC%A0%9C-1%EC%9E%A5-%EB%B9%85%EB%8D%B0%EC%9D%B4%ED%84%B0-%EA%B8%B0%EC%B4%88-%EC%A7%80%EC%8B%9D\" aria-label=\"제 1장 빅데이터 기초 지식 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>제 1장. 빅데이터 기초 지식</h2>\n<br />\n<ul>\n<li><strong>데이터란?</strong></li>\n</ul>\n<p>Hadoop과 NoSQL’데이터베이스 분산 시스템 기술’이 확립되어 기존의 ‘데이터 웨어하우스’를 보완 대체하며 발생한 것</p>\n<ul>\n<li><strong>데이터 레이크</strong></li>\n</ul>\n<p>다양한 데이터를 축적하는 스토리지를 ‘데이터가 흘러가는 호수’에 빗대어 사용하는 말</p>\n<ul>\n<li><strong>데이터 웨어하우스</strong></li>\n</ul>\n<p>사용자의 의사결정에 필요한 데이터가 들어있는 데이터 베이스(엔터프라이스 데이터 웨어하우스)</p>\n<ul>\n<li><strong>데이터 디스커버리 = 셀프서비스 용 BI 도구</strong></li>\n</ul>\n<p>데이터 웨어하우스에 저장된 데이터를 시각화하려는 방법</p>\n<ul>\n<li><strong>데이터 파이프라인</strong></li>\n</ul>\n<p>일반적으로 차례대로 전달해나가는 데이터로 구성된 시스템</p>\n<br />\n<hr>\n<p>데이터 수집 및 전송을 위한 방법은 크게 두 가지로 나뉩니다.</p>\n<ul>\n<li><strong>벌크형</strong></li>\n</ul>\n<p>이미 어딘가에 존재하는 데이터를 정리해 추출하는 방법</p>\n<ul>\n<li><strong>스트리밍형</strong></li>\n</ul>\n<p>차례대로 생성되는 데이터를 끊임없이 계속해서 보내는 방법</p>\n<br />\n<hr>\n<br />\n<ul>\n<li><strong>분산스토리지</strong></li>\n</ul>\n<p>여러 컴퓨터와 디스크로부터 구성된 스토리지 시스템\r\n(객체 스토리지(Amazon S3), NoSQL(MongoDB) 등 가능)</p>\n<p>분산 데이터 처리를 위해서는 분산 데이터 처리 프레임워크가 필요합니다.</p>\n<p>MapReduce가 사용된 부분이 바로 이 과정이고 많은 컴퓨터 자원을 필요로 합니다.</p>\n<br />\n<hr>\n<br />\n<p>빅데이터 집계를 위해 SQL을 통해 집계를 하는 경우 두가지 방법이 존재합니다.</p>\n<ol>\n<li>\n<p>쿼리 엔진을 도입(예를들어 Hive 혹은 대화형 쿼리 엔진)</p>\n</li>\n<li>\n<p>데이터 웨어하우스 제품 이용</p>\n</li>\n</ol>\n<p>분산 스토리지에서 추출한 데이터를 데이터 웨어하우스에서 적합한 형식으로 변환합니다. 이 절차를 ETL(Extract, Transform, Load) 프로세스 라고 합니다.</p>\n<ul>\n<li>워크플로 관리</li>\n</ul>\n<p>전체 데이터 파이프라인의 동작을 관리하기 위해 정해진 시간에 배치 처리를 스케줄대로 실행</p>\n<br />\n<hr>\n<br />\n<h3 id=\"데이터-웨어하우스와-데이터-마트에-대하여\" style=\"position:relative;\"><a href=\"#%EB%8D%B0%EC%9D%B4%ED%84%B0-%EC%9B%A8%EC%96%B4%ED%95%98%EC%9A%B0%EC%8A%A4%EC%99%80-%EB%8D%B0%EC%9D%B4%ED%84%B0-%EB%A7%88%ED%8A%B8%EC%97%90-%EB%8C%80%ED%95%98%EC%97%AC\" aria-label=\"데이터 웨어하우스와 데이터 마트에 대하여 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>데이터 웨어하우스와 데이터 마트에 대하여</h3>\n<br />\n<p>데이터 웨어하우스는 ‘대량의 데이터를 장기 보존’하는 것에 최적화 되어있고, 소형의 데이터를 매번 추출하는 데 있어서는 적합하지 않습니다.</p>\n<br />\n<p>즉, 데이터 분석과 같은 목적에 있어 사용하는 경우에는 데이터 웨어하우스에서 필요한 데이터를 추출해 <strong>데이터 마트</strong>를 구축합니다.</p>\n<br />\n<p>이러한 데이터 마트는 BI 도구와 조합시키는 형태로 사용됩니다.</p>\n<br />\n<ul>\n<li><strong>데이터 레이크 추가 설명</strong></li>\n</ul>\n<p>데이터 웨어하우스에 넣을 수 없는 텍스트 파일 혹은 바이너리 데이터 등은 데이터 레이크에 축적됩니다.</p>\n<br />\n<p>구체적으로는 임의의 데이터를 저장할 수 있는 <strong>분산 스토리지</strong>가 데이터 레이크로 이용됩니다.</p>\n<br />\n<ul>\n<li><strong>데이터 레이크와 데이터 마트</strong></li>\n</ul>\n<br />\n<p>데이터 레이크는 단순 스토리지이기에 가공할 수 없어 분산 데이터 처리 기술이 또한 필요합니다.</p>\n<br />\n<p>따라서 데이터 웨어하우스의 경우처럼 데이터 마트를 추출해 사용하는 것이 일반적입니다.</p>\n<br />\n<p>데이터 소스(수집) - 데이터 웨어 하우스 - 데이터 마트 - BI도구</p>\n<p>데이터 소스(수집) - 데이터 레이크(분산 스토리지) - 데이터 마트 - BI도구</p>\n<br />\n<hr>\n<br />\n<ul>\n<li><strong>애드 혹 분석</strong></li>\n</ul>\n<p>일회성 데이터 분석</p>\n<ul>\n<li><strong>대시보드 도구</strong></li>\n</ul>\n<p>정기적으로 그래프와 보고서를 만드려는 경우 도입</p>\n<br />\n<hr>\n<br />\n<p>데이터 전처리에 사용하는 스크립트 언어 : R, 파이썬</p>\n<p>특히 파이썬의 DataFrame은 SQL 결과를 불러들여올 수 있어 활용도가 매우 높습니다.</p>\n<br />\n<ul>\n<li>무료로 사용할 수 있는 BI도구</li>\n</ul>\n<p>Tableau Public, Quick Sencse, Microsoft Power BI, 구글 Data Studio</p>\n<p>원하는 집계 결과를 얻기 위해서는 항상 ‘사각화하기 쉬운 데이터’를 만들어야 함을 명심해야 합니다.</p>\n<br />\n<hr>\n<br />\n<h2 id=\"제2장-빅데이터의-탐색\" style=\"position:relative;\"><a href=\"#%EC%A0%9C2%EC%9E%A5-%EB%B9%85%EB%8D%B0%EC%9D%B4%ED%84%B0%EC%9D%98-%ED%83%90%EC%83%89\" aria-label=\"제2장 빅데이터의 탐색 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>제2장. 빅데이터의 탐색</h2>\n<br />\n<ul>\n<li><strong>크로스 테이블</strong></li>\n</ul>\n<p>행과 열이 교차하는 부분에 숫자 데이터가 들어갑니다.</p>\n<p>특징은 열방향으로 데이터가 증가합니다.</p>\n<br />\n<ul>\n<li><strong>트랜잭션 테이블</strong></li>\n</ul>\n<p>열방향으로 데이터를 증가하지 않도록 하는 테이블입니다.</p>\n<br />\n<ul>\n<li><strong>크로스 집계</strong></li>\n</ul>\n<p>트랜젝션 테이블에서 크로스 테이블로 변환하는 과정을 이르킵니다.</p>\n<p>크로스 집계에 있어서는 다양한 방법이 이용됩니다.</p>\n<p>이 책에서 소개하는 방법은 다음과 같습니다.</p>\n<br />\n<ol>\n<li>\n<p><strong>피벗 테이블 기능에 의한 크로스 집계</strong></p>\n<p>Excel의 피벗 테이블을 통한 크로스 집계가 가능합니다.</p>\n</li>\n</ol>\n<br />\n<ol start=\"2\">\n<li><strong>BI 도구에 의한 크로스 집계</strong></li>\n</ol>\n<br />\n<ol start=\"3\">\n<li>\n<p><strong>Pandas에 의한 크로스 집계</strong></p>\n<p>크로스 집계를 위해서 pandas를 이용할 수 있습니다.</p>\n<p>새로 추가하고자 하는 데이터가 있다면 dataFrame을 통한 처리가 가능합니다.</p>\n<p>merge()함수를 통해 데이터를 추가하고 pivot_table()을 통해 크로스 집계를 실시 합니다.</p>\n</li>\n</ol>\n<br />\n<ol start=\"4\">\n<li>\n<p><strong>SQL에 의한 테이블의 집계</strong></p>\n<p>피벗 테이블을 쉬우나 데이터가 너무 많으면 처리할 수 없고, BI도구와 Pandas또한 수백만 레코드 이상이 넘어간다면 집계에 시간이 너무 걸려 사용하기 어렵습니다.</p>\n<p>대량의 데이터를 크로스 집계하기 위해서는 SQL을 사용해 데이터 집계를 실시합니다. sum()과 같은 집계함수가 그 예입니다.</p>\n<p>즉, SQL을 통해 데이터를 집계하고(이때 만들어지는 것은 트랜젝션 테이블) 이 만들어진 테이블을 BI도구를 통해 크로스 집계하는 것입니다.</p>\n<p>이론상으로는 무한히 많은 데이터가 있더라도 SQL과 시각화 도구를 결합함으로써 크로스 집계를 수행할 수 있습니다.</p>\n</li>\n</ol>\n<br />\n<hr>\n<h3 id=\"열-지향-스토리지에-의한-고속화\" style=\"position:relative;\"><a href=\"#%EC%97%B4-%EC%A7%80%ED%96%A5-%EC%8A%A4%ED%86%A0%EB%A6%AC%EC%A7%80%EC%97%90-%EC%9D%98%ED%95%9C-%EA%B3%A0%EC%86%8D%ED%99%94\" aria-label=\"열 지향 스토리지에 의한 고속화 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>열 지향 스토리지에 의한 고속화</h3>\n<br />\n<p>데이터 마트를 만드는데 있어 가급적 지연이 적은 데이터 베이스를 선택해야는데 여기에는 두가지 선택이 있습니다.</p>\n<ol>\n<li>모든 데이터를 메모리에 올린다.\r\n들어맞는 정도의 데이터 양이라면 그다지 지연은 발생하지 않습니다.\r\nRDB의 경우 메모리 양만 적절하다면 데이터 마트에 적합합니다. 다만 메모리가 역으로 부족하다면 성능이 급격히 저하됩니다.</li>\n</ol>\n<br />\n<ol start=\"2\">\n<li><strong>MPP 아키텍처에 의한 데이터 처리의 병렬화</strong> 💡</li>\n</ol>\n<br />\n<hr>\n<p>고속화를 위해 사용하는 기법은 ‘압축’과 ‘분산’입니다.</p>\n<br />\n<p>📘 <strong>분산</strong></p>\n<p>분산된 데이터를 읽어 들이려면 멀티 코어를 활용하며 디스크 I/O를 병렬 처리하는 것이 효과적입니다.</p>\n<p>이러한 아키텍처를 <strong>MPP(massive parellel processing)</strong> 이라고 합니다.</p>\n<p>예를 들어 <strong>Amazon RedShift</strong> 및 <strong>Google BigQuery</strong> 등이 이러한 MPP 아키텍처 기반입니다.</p>\n<p>MPP는 데이터 집계에 최적화되어 있고, 클라우드 서비스의 보급과 함께 더욱 널리 이용되고 있습니다.</p>\n<br />\n<p>📙 <strong>압축</strong></p>\n<p>압축을 위해서는 ‘열 지향’의 개념을 알아야 합니다.</p>\n<p>디스크 상의 최소한의 데이터를 쿼리를 통해 가져와야 지연을 최대로 줄일 수 있습니다.</p>\n<p>일반적인 레코드 단위의 데이터 베이스는 <strong>행 지향 데이터베이스</strong> 라고 부릅니다. 이는 RDB가 대표적이죠.</p>\n<p>이에 반해 데이터 분석 시 사용되는 칼럼 단위의 집계에 최적화된 데이터베이스를 <strong>열 지향 데이터 베이스</strong> 라고 합니다.</p>\n<p>여기서 헷갈리면 안되는게 칼럼 단위로 데이터를 저장한다는 것은 행/열을 바꾸는게 아니라, 저장 단위만이 바뀐다는 것입니다.</p>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 720px; \"\n    >\n      <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 53.333333333333336%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAALCAIAAADwazoUAAAACXBIWXMAAB2HAAAdhwGP5fFlAAABHklEQVQoz6XRS2/DMAgA4P7/HzdphyrbnHdiAzbOy3k0lRx2qLRuuexQLsDhEwIu8kJcHmnfd0QkIkK0YLTWAECEhAgIWmuy1rUFgiFrn/g4DhFh5labsKy9w9A7leVgecJ6MjlYp9IshNCnb2PHKstjjH+wZ25zNVjjoRkZ1fXdlOlgzWCNKVN1fR8deDIdtSq5PsgTd54DlbLxEUg276vkxrWsLAvfXO3LRFZ/TCSzpeIjxjP2E5QycxxJFu+KZLW1zCxrt3Lrqk/Z+hicLIzl1xl75tFpuc9xHeQ+U50uHcoeZBu3nqhScpvi0ss26kKddw4hVHUDSNoAklVpVjctIAFS02qVZoBkALXBsqrOr3rpzz8H/Lf9Xb80+RtItXfa0B9dpwAAAABJRU5ErkJggg=='); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"행 지향 DB\"\n        title=\"행 지향 DB\"\n        src=\"/static/5aef461f131049c218ea8b6d6dc3ff9b/37523/%ED%96%89%EC%A7%80%ED%96%A5.png\"\n        srcset=\"/static/5aef461f131049c218ea8b6d6dc3ff9b/e9ff0/%ED%96%89%EC%A7%80%ED%96%A5.png 180w,\n/static/5aef461f131049c218ea8b6d6dc3ff9b/f21e7/%ED%96%89%EC%A7%80%ED%96%A5.png 360w,\n/static/5aef461f131049c218ea8b6d6dc3ff9b/37523/%ED%96%89%EC%A7%80%ED%96%A5.png 720w,\n/static/5aef461f131049c218ea8b6d6dc3ff9b/eba85/%ED%96%89%EC%A7%80%ED%96%A5.png 1054w\"\n        sizes=\"(max-width: 720px) 100vw, 720px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n        decoding=\"async\"\n      />\n    </span>\r\n<span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 720px; \"\n    >\n      <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 53.333333333333336%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAALCAIAAADwazoUAAAACXBIWXMAAB2HAAAdhwGP5fFlAAABSUlEQVQoz6WSS2/CMAzH+f5fZqcddpk0gTQ2cRiFUbrSF83LcduVhhbxaDK1rEMdaJdZfyVy7J+dyBmYf9jgvO33ByERMAGJEoBw4IAgJUjJBRImAFNkawEAmFxgrbUxJkWgvlMk8Bm7ivuBPU1oqOLlNppJuo6W0zITG3ukYO07i/p06sEZ8chikos4JV6OPHh5SOZDlQqFBAM7Ht2VSDdAFLLQGusqb1nddSZBkYjmoK6NMdJ/r4R/Ll+pQi7GTajN5JFXb7MenNGgkMwYUx+PDezOKvrRwbmcjZpQW5eF7m84ib0NtnDdvEe4VtnBu1KJ6dMPTDynVmkPVsii+YQHLl3ZPPT810f6NmTBivkOcazo+Z67FnMt6lqhNTaHqjeqxg47s9+afdmsx13rlt/SJ2N0p6s56/70/3Dbi+qrzpfaN3Xjh30Bxgp1U18kUwkAAAAASUVORK5CYII='); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"열 지향 DB\"\n        title=\"열 지향 DB\"\n        src=\"/static/0e870cb730d10a10c181808e4e2a64e1/37523/%EC%97%B4%EC%A7%80%ED%96%A5.png\"\n        srcset=\"/static/0e870cb730d10a10c181808e4e2a64e1/e9ff0/%EC%97%B4%EC%A7%80%ED%96%A5.png 180w,\n/static/0e870cb730d10a10c181808e4e2a64e1/f21e7/%EC%97%B4%EC%A7%80%ED%96%A5.png 360w,\n/static/0e870cb730d10a10c181808e4e2a64e1/37523/%EC%97%B4%EC%A7%80%ED%96%A5.png 720w,\n/static/0e870cb730d10a10c181808e4e2a64e1/eba85/%EC%97%B4%EC%A7%80%ED%96%A5.png 1054w\"\n        sizes=\"(max-width: 720px) 100vw, 720px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n        decoding=\"async\"\n      />\n    </span></p>\n<p>대표적으로 <strong>Teradata(테라데이터)</strong> 와 <strong>Amazon RedShift</strong> 등이 열 지향 데이터 베이스입니다.</p>\n<br />\n<p>행 지향 데이터 베이스는 인덱스를 통해 데이터 검색을 합니다. 하지만 데이터 분석 시는 어떤 칼럼이 사용되는 지 알 수 없어 이러한 인덱스 작성은 크게 효율적이지 않고 많은 디스크 I/O를 동반합니다.</p>\n<br />\n<p>따라서 필요한 칼럼만을 로드하여 디스크 I/O를 줄이는 방법이 필요한데 이 부분에서 열 지향 데이터베이스가 큰 역할을 차지합니다.</p>\n<br />\n<p>바로 같은 칼럼에 대해서 같은 문자열 반복을 매우 작게 압축할 수 있다는 겁니다. 이는 압축되지 않은 행 지향 데이터베이스와 비교해 1/10 이하로 압축이 가능합니다.</p>\n<br />\n<hr>\n<br />\n<h3 id=\"mpp-아키텍처에-의한-데이터-처리의-병렬화-과정\" style=\"position:relative;\"><a href=\"#mpp-%EC%95%84%ED%82%A4%ED%85%8D%EC%B2%98%EC%97%90-%EC%9D%98%ED%95%9C-%EB%8D%B0%EC%9D%B4%ED%84%B0-%EC%B2%98%EB%A6%AC%EC%9D%98-%EB%B3%91%EB%A0%AC%ED%99%94-%EA%B3%BC%EC%A0%95\" aria-label=\"mpp 아키텍처에 의한 데이터 처리의 병렬화 과정 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>MPP 아키텍처에 의한 데이터 처리의 병렬화 과정</h3>\n<br />\n<p>행 지향 데이터베이스는 보통 하나의 쿼리, 즉 개별 쿼리는 분산되지 않습니다. 여러 개의 쿼리를 멀티 코어를 통해 활용할 수 있지만 한 쿼리 당 하나의 CPU가 도맡습니다.</p>\n<br />\n<p>반면 열 지향 데이터 데이터베이스라면 다릅니다. MPP에서는 하나의 쿼리를 다수의 태스크로 나눕니다. 그리고 이를 병렬로 실행합니다.</p>\n<br />\n<p>가령 1억개의 레코드로 구성된 테이블의 합계를 구하기 위해 10만 레코드를 1000개의 태스크로 나누어 각 CPU가 병렬로 집계를 수행합니다.</p>\n<br />\n<p>그리고 각 10만 레코드의 합계를 집계해 마지막 모든 결과를 모아 총 합계를 계산합니다.</p>\n<br />\n<p>즉, MPP를 사용한 데이터 집계는 CPU 코어 수에 비례한다는 것입니다.</p>\n<br />\n<p>MPP는 그 구조 상, 고속화를 위해서 하드웨어, 소프트웨어 모두 균형있게 늘려야 합니다.(이유는 디스크, CPU모두 병렬 사용)</p>\n<br />\n<p>이처럼 하드웨어 수준에서 데이터 집계에 최적화된 데이터베이스를 <strong>MPP데이터베이스</strong> 라고 합니다.</p>\n<br />\n<hr>\n<br />\n<p>MPP 아키텍처는 Hodoop과 함께 사용되는 ‘대화형 쿼리 엔진’으로도 채택되고 있습니다.</p>\n<br />\n<p>이는 데이터를 저장하는 분산 스토리지로써의 역할이죠.(데이터 레이크)</p>\n<p>하지만 앞서 MPP 데이터베이스의 ‘압축’의 역할을 하지 못한다면 MPP 데이터베이스와 동일한 성능을 가지지 못합니다.</p>\n<br />\n<p>안정성과 서프트 체제의 측면에서는 상용 MPP 데이터베이스</p>\n<br />\n<p>Hadoop과의 궁합을 고려한다면 대화형 쿼리 엔진 쪽을 선택하면 됩니다.</p>\n<br />\n<hr>\n<h3 id=\"mpp-데이터베이스열-지향-db-및-인-메모리-데이터베이스-등장-전후\" style=\"position:relative;\"><a href=\"#mpp-%EB%8D%B0%EC%9D%B4%ED%84%B0%EB%B2%A0%EC%9D%B4%EC%8A%A4%EC%97%B4-%EC%A7%80%ED%96%A5-db-%EB%B0%8F-%EC%9D%B8-%EB%A9%94%EB%AA%A8%EB%A6%AC-%EB%8D%B0%EC%9D%B4%ED%84%B0%EB%B2%A0%EC%9D%B4%EC%8A%A4-%EB%93%B1%EC%9E%A5-%EC%A0%84%ED%9B%84\" aria-label=\"mpp 데이터베이스열 지향 db 및 인 메모리 데이터베이스 등장 전후 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>MPP 데이터베이스(열 지향 DB) 및 인 메모리 데이터베이스 등장 전후</h3>\n<br />\n<ul>\n<li><strong>이전의 경우</strong></li>\n</ul>\n<p>데이터 분석을 위해 만들어진 다차원 데이터 OLAP 큐브를 MDX라는 쿼리언어를 통해 크로스 집계하는 구조가 있습니다.</p>\n<br />\n<p>MPP 데이터베이스가 없던 시절에는 이러한 OLAP구조를 고속화하는 방식으로 집계 성능을 올리곤 했습니다.</p>\n<br />\n<p>그렇기에 미리 데이터 마트 및 BI 도구는 OLAP구조에 맞추어 여러 크로스 집계 조합을 미리 계산해 두어 이를 실현하고자 했습니다.</p>\n<br />\n<ul>\n<li><strong>이후의 경우</strong></li>\n</ul>\n<p>MPP 데이터베이스와 인 메모리 데이터베이스의 보급이후, 이러한 OLAP의 개념 대신 <strong>비 정규화 테이블</strong>을 통해 BI도구에서 OLAP와 동등한 성능을 보장할 수 있게 되었습니다.</p>\n<br />\n<hr>\n<h2 id=\"테이블-비정규화하기\" style=\"position:relative;\"><a href=\"#%ED%85%8C%EC%9D%B4%EB%B8%94-%EB%B9%84%EC%A0%95%EA%B7%9C%ED%99%94%ED%95%98%EA%B8%B0\" aria-label=\"테이블 비정규화하기 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>테이블 비정규화하기</h2>\n<ul>\n<li><strong>트랜잭션</strong></li>\n</ul>\n<p>시간과 함께 생성되는 데이터</p>\n<ul>\n<li><strong>마스터</strong></li>\n</ul>\n<p>트랜잭션에서 참고되는 각종 정보</p>\n<ul>\n<li><strong>팩트 테이블</strong></li>\n</ul>\n<p>트랜잭션처럼 사실이 기록된 테이블</p>\n<ul>\n<li><strong>디멘전 테이블</strong></li>\n</ul>\n<p>마스터 데이터들</p>\n<ul>\n<li><strong>스타스키마</strong></li>\n</ul>\n<p>팩트 테이블을 중심으로 여러 디멘전 테이블을 결합한 구조</p>\n<ul>\n<li><strong>비정규화</strong></li>\n</ul>\n<p>정규화와는 반대의 작업</p>\n<br />\n<p>전통적인 RDB를 데이터 마트로 사용하기엔 쿼리지연이 너무나 많이 일어납니다.</p>\n<p>따라서 정규화된 RDB 대신 비정규화 데이터베이스 -> BI도구를 통한 크로스 집계를 합니다.</p>\n<p>스타스키마만 사용하던 이전과는 달리 스타스키마에서 조금 더 비정규화를 진행한 비정규화 테이블을 통해 데이터 마트를 준비할 수 있습니다.</p>\n<p>이러한 비정규화 테이블은 <strong>다차원 모델</strong>이라는 이름으로 추상화합니다.</p>\n<p>이는 테이블 및 디멘전의 집합을 쉽게 알 수 있기 때문입니다.</p>\n<p>각 칼럼은 <strong>디멘전</strong>과 <strong>측정값</strong>으로 나뉩니다.</p>\n<p>이 구조를 통해 BI도구에서 크로스 집계가 가능한 것이지요.</p>\n<p>즉, 전통적인 OLAP에 의한 데이터 집계처럼 비정규화를 통한 다차원 모델을 만들어 데이터 분석 및 크로스 집계를 하는 겁니다.</p>\n<hr>\n<p><strong>정리</strong></p>\n<ul>\n<li>데이터 마트를 작성하는 경우, 팩트 테이블, 디멘전 테이블을 모두 결합한 비정규화 테이블을 만듭니다. 테이블의 내용이 메모리에 실릴 정도로 작다면 RDB를 데이터 마트로 사용할 수 있으나, 그렇지 않다면 ‘MPP 데이터베이스’ 등의 열 지향 스토리지를 이용하는 것이 좋습니다.</li>\n</ul>\n<br />\n<ul>\n<li>BI 도구로 비정규화 테이블을 오픈하여 전통적인 OLAP에 의한 데이터 집계 처럼 다차원 모델을 통해 측정값과 디멘전으로 분류하여 데이터 분석 및 크로스 집계를 대량으로 수행할 수 있습니다.</li>\n</ul>\n<br />","frontmatter":{"date":"February 09, 2023","title":"빅 데이터를 지탱하는 기술 책 리뷰 - (1)","categories":"Engineer","author":"DEVEL","emoji":"😸"},"fields":{"slug":"/data-engineering-1/"}},"prev":null,"site":{"siteMetadata":{"siteUrl":"https://hsjni0110.github.io/devel-repo","comments":{"utterances":{"repo":"hsjni0110/hsjni0110.github.io"}}}}},"pageContext":{"slug":"/data-engineer-3/","nextSlug":"/data-engineering-1/","prevSlug":""}},"staticQueryHashes":["1073350324","1956554647","2938748437"]}